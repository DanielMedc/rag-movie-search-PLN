{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Sistema RAG com um Self-Querying Retriever em LangChain para busca de Filmes***"
      ],
      "metadata": {
        "id": "BJiL6hmCzqEl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse Colab foi criado com base em um artigo publicado por Ed Izaguirre no Medium.\n",
        "\n",
        "[Clique aqui para ler o artigo completo](https://towardsdatascience.com/how-to-build-a-rag-system-with-a-self-querying-retriever-in-langchain-16b4fa23e9ad)\n"
      ],
      "metadata": {
        "id": "jVOvQV8az0OJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introdução"
      ],
      "metadata": {
        "id": "yzali1vG4nS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta apresentação, vamos explorar como criar um sistema de busca de filmes utilizando a técnica RAG (Retrieval-Augmented Generation) com um Self-Querying Retriever, implementado na biblioteca LangChain. A ideia surgiu a partir de uma frustração comum: a dificuldade de encontrar filmes que correspondam exatamente ao que estamos procurando, usando apenas o título ou o nome de atores. O objetivo é permitir que os usuários façam buscas mais naturais e específicas, como “recomende filmes de comédia com zumbis” ou “encontre dramas curtos em inglês com animais de estimação”, sem precisar depender de recomendações baseadas em histórico de visualização."
      ],
      "metadata": {
        "id": "jaVCfMd84U31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O sistema que vamos construir combina a simplicidade e a privacidade de uma busca baseada em consultas de linguagem natural com a eficiência de um filtro por metadados. Primeiro, ele filtra os filmes com base nos critérios especificados pelo usuário, como gênero ou data de lançamento, e em seguida, realiza uma busca de similaridade para encontrar títulos que correspondam ao tom ou conteúdo desejado. Ao longo deste Colab, iremos passo a passo construir esse sistema, com todo o código necessário para você implementar e personalizar essa solução em seus próprios projetos."
      ],
      "metadata": {
        "id": "R4OX1ua_4UUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uma visão técnica do projeto"
      ],
      "metadata": {
        "id": "USRPSYra4yBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizamos o LangChain, uma poderosa biblioteca para a construção de sistemas de Recuperação Aumentada por Geração (RAG), integrando-a com o Pinecone, um banco de dados vetorial que permite buscas rápidas e eficientes por similaridade. A técnica central é o uso de um Self-Querying Retriever, que permite filtrar os filmes por metadados antes de realizar a busca por similaridade. Além disso, utilizamos os modelos GPT-4o e GPT-4o-mini da OpenAI para construir um sistema de recomendação baseado em consultas em linguagem natural. A API do The Movie Database (TMDB) foi a fonte dos dados, fornecendo uma base de filmes com diversas informações que foram essenciais para a personalização das buscas. Todos esses componentes foram integrados em um pipeline que permite uma experiência de busca de filmes sem a necessidade de histórico de usuário."
      ],
      "metadata": {
        "id": "R3u1dJ2X5tVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Instalação de dependências**"
      ],
      "metadata": {
        "id": "B-nP1cg1hYc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Escrita do arquivo requirements.txt"
      ],
      "metadata": {
        "id": "hqftCdRmqxki"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ferohLPrVp5e",
        "outputId": "a953c915-58e1-4bab-d8ae-ec5f1fd28867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "aiohttp==3.9.3\n",
        "aiosignal==1.3.1\n",
        "altair==5.2.0\n",
        "annotated-types==0.6.0\n",
        "anyio==4.3.0\n",
        "appnope==0.1.4\n",
        "argon2-cffi==23.1.0\n",
        "argon2-cffi-bindings==21.2.0\n",
        "arrow==1.3.0\n",
        "asgiref==3.8.0\n",
        "asttokens==2.4.1\n",
        "async-lru==2.0.4\n",
        "attrs==23.2.0\n",
        "Babel==2.14.0\n",
        "backoff==2.2.1\n",
        "bcrypt==4.1.2\n",
        "beautifulsoup4==4.12.3\n",
        "bleach==6.1.0\n",
        "blinker==1.7.0\n",
        "build==1.1.1\n",
        "cachetools==5.3.3\n",
        "certifi==2024.2.2\n",
        "cffi==1.16.0\n",
        "charset-normalizer==3.3.2\n",
        "chroma-hnswlib==0.7.3\n",
        "click==8.1.7\n",
        "coloredlogs==15.0.1\n",
        "comm==0.2.1\n",
        "dataclasses-json==0.6.4\n",
        "debugpy==1.8.1\n",
        "decorator==5.1.1\n",
        "defusedxml==0.7.1\n",
        "Deprecated==1.2.14\n",
        "distro==1.9.0\n",
        "executing==2.0.1\n",
        "fastapi==0.110.0\n",
        "fastjsonschema==2.19.1\n",
        "filelock==3.13.1\n",
        "flatbuffers==24.3.7\n",
        "fqdn==1.5.1\n",
        "frozenlist==1.4.1\n",
        "fsspec==2024.2.0\n",
        "gitdb==4.0.11\n",
        "GitPython==3.1.42\n",
        "google-auth==2.29.0\n",
        "googleapis-common-protos==1.63.0\n",
        "grpcio==1.62.1\n",
        "h11==0.14.0\n",
        "httpcore==1.0.4\n",
        "httptools==0.6.1\n",
        "httpx==0.27.0\n",
        "huggingface-hub==0.21.4\n",
        "humanfriendly==10.0\n",
        "idna==3.6\n",
        "importlib-metadata==6.11.0\n",
        "importlib_resources==6.4.0\n",
        "ipykernel==6.29.3\n",
        "ipython==8.22.2\n",
        "ipywidgets==8.1.2\n",
        "iso-639==0.4.5\n",
        "isoduration==20.11.0\n",
        "jedi==0.19.1\n",
        "Jinja2==3.1.3\n",
        "json5==0.9.22\n",
        "jsonpatch==1.33\n",
        "jsonpointer==2.4\n",
        "jsonschema==4.21.1\n",
        "jsonschema-specifications==2023.12.1\n",
        "jupyter==1.0.0\n",
        "jupyter-console==6.6.3\n",
        "jupyter-events==0.9.0\n",
        "jupyter-lsp==2.2.4\n",
        "jupyter_client==8.6.0\n",
        "jupyter_core==5.7.1\n",
        "jupyter_server==2.13.0\n",
        "jupyter_server_terminals==0.5.2\n",
        "jupyterlab==4.1.4\n",
        "jupyterlab_pygments==0.3.0\n",
        "jupyterlab_server==2.25.3\n",
        "jupyterlab_widgets==3.0.10\n",
        "kubernetes==29.0.0\n",
        "langchain==0.1.13\n",
        "langchain-community==0.0.29\n",
        "langchain-core==0.1.33\n",
        "langchain-experimental==0.0.54\n",
        "langchain-openai==0.0.8\n",
        "langchain-pinecone==0.0.3\n",
        "langchain-text-splitters==0.0.1\n",
        "langsmith==0.1.23\n",
        "lark==1.1.9\n",
        "markdown-it-py==3.0.0\n",
        "MarkupSafe==2.1.5\n",
        "marshmallow==3.21.1\n",
        "matplotlib-inline==0.1.6\n",
        "mdurl==0.1.2\n",
        "mistune==3.0.2\n",
        "mmh3==4.1.0\n",
        "monotonic==1.6\n",
        "mpmath==1.3.0\n",
        "multidict==6.0.5\n",
        "mypy-extensions==1.0.0\n",
        "nbclient==0.9.0\n",
        "nbconvert==7.16.2\n",
        "nbformat==5.9.2\n",
        "neo4j==5.18.0\n",
        "nest-asyncio==1.6.0\n",
        "notebook==7.1.1\n",
        "notebook_shim==0.2.4\n",
        "numpy==1.26.4\n",
        "oauthlib==3.2.2\n",
        "onnxruntime==1.17.1\n",
        "openai==1.13.3\n",
        "opentelemetry-api==1.23.0\n",
        "opentelemetry-exporter-otlp-proto-common==1.23.0\n",
        "opentelemetry-exporter-otlp-proto-grpc==1.23.0\n",
        "opentelemetry-instrumentation==0.44b0\n",
        "opentelemetry-instrumentation-asgi==0.44b0\n",
        "opentelemetry-instrumentation-fastapi==0.44b0\n",
        "opentelemetry-proto==1.23.0\n",
        "opentelemetry-sdk==1.23.0\n",
        "opentelemetry-semantic-conventions==0.44b0\n",
        "opentelemetry-util-http==0.44b0\n",
        "orjson==3.9.15\n",
        "overrides==7.7.0\n",
        "packaging==23.2\n",
        "pandas==2.2.1\n",
        "pandocfilters==1.5.1\n",
        "parso==0.8.3\n",
        "pexpect==4.9.0\n",
        "pillow==10.2.0\n",
        "pinecone-client==3.1.0\n",
        "platformdirs==4.2.0\n",
        "posthog==3.5.0\n",
        "prometheus_client==0.20.0\n",
        "prompt-toolkit==3.0.43\n",
        "protobuf==4.25.3\n",
        "psutil==5.9.8\n",
        "ptyprocess==0.7.0\n",
        "pulsar-client==3.4.0\n",
        "pure-eval==0.2.2\n",
        "pyarrow==15.0.2\n",
        "pyasn1==0.5.1\n",
        "pyasn1-modules==0.3.0\n",
        "pycparser==2.21\n",
        "pydantic==2.6.3\n",
        "pydantic_core==2.16.3\n",
        "pydeck==0.8.1b0\n",
        "Pygments==2.17.2\n",
        "PyPika==0.48.9\n",
        "pyproject_hooks==1.0.0\n",
        "python-dateutil==2.9.0.post0\n",
        "python-dotenv==1.0.1\n",
        "python-json-logger==2.0.7\n",
        "pytz==2024.1\n",
        "PyYAML==6.0.1\n",
        "pyzmq==25.1.2\n",
        "qtconsole==5.5.1\n",
        "QtPy==2.4.1\n",
        "referencing==0.33.0\n",
        "regex==2023.12.25\n",
        "requests==2.31.0\n",
        "requests-oauthlib==1.4.0\n",
        "rfc3339-validator==0.1.4\n",
        "rfc3986-validator==0.1.1\n",
        "rich==13.7.1\n",
        "rpds-py==0.18.0\n",
        "rsa==4.9\n",
        "safetensors==0.4.2\n",
        "Send2Trash==1.8.2\n",
        "setuptools==68.2.2\n",
        "six==1.16.0\n",
        "smmap==5.0.1\n",
        "sniffio==1.3.1\n",
        "soupsieve==2.5\n",
        "SQLAlchemy==2.0.28\n",
        "stack-data==0.6.3\n",
        "starlette==0.36.3\n",
        "streamlit==1.32.2\n",
        "sympy==1.12\n",
        "tabulate==0.9.0\n",
        "tenacity==8.2.3\n",
        "terminado==0.18.0\n",
        "tiktoken==0.6.0\n",
        "tinycss2==1.2.1\n",
        "tokenizers==0.15.2\n",
        "toml==0.10.2\n",
        "toolz==0.12.1\n",
        "tornado==6.4\n",
        "tqdm==4.66.2\n",
        "traitlets==5.14.1\n",
        "transformers==4.38.2\n",
        "typer==0.9.0\n",
        "types-python-dateutil==2.8.19.20240106\n",
        "typing-inspect==0.9.0\n",
        "typing_extensions==4.10.0\n",
        "tzdata==2024.1\n",
        "uri-template==1.3.0\n",
        "urllib3==2.2.1\n",
        "uvicorn==0.29.0\n",
        "uvloop==0.19.0\n",
        "watchfiles==0.21.0\n",
        "wcwidth==0.2.13\n",
        "webcolors==1.13\n",
        "webencodings==0.5.1\n",
        "websocket-client==1.7.0\n",
        "websockets==12.0\n",
        "wheel==0.41.2\n",
        "widgetsnbextension==4.0.10\n",
        "wrapt==1.16.0\n",
        "yarl==1.9.4\n",
        "zipp==3.18.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalação"
      ],
      "metadata": {
        "id": "g3Qy1yXvq4ME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG4pb7E3WmOW",
        "outputId": "9ca5b0dc-387d-4334-c373-9032f8e2be06",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aiohttp==3.9.3 (from -r requirements.txt (line 1))\n",
            "  Downloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: aiosignal==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.3.1)\n",
            "Collecting altair==5.2.0 (from -r requirements.txt (line 3))\n",
            "  Downloading altair-5.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting annotated-types==0.6.0 (from -r requirements.txt (line 4))\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting anyio==4.3.0 (from -r requirements.txt (line 5))\n",
            "  Downloading anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting appnope==0.1.4 (from -r requirements.txt (line 6))\n",
            "  Downloading appnope-0.1.4-py2.py3-none-any.whl.metadata (908 bytes)\n",
            "Requirement already satisfied: argon2-cffi==23.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (23.1.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (21.2.0)\n",
            "Collecting arrow==1.3.0 (from -r requirements.txt (line 9))\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting asgiref==3.8.0 (from -r requirements.txt (line 10))\n",
            "  Downloading asgiref-3.8.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting asttokens==2.4.1 (from -r requirements.txt (line 11))\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting async-lru==2.0.4 (from -r requirements.txt (line 12))\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting attrs==23.2.0 (from -r requirements.txt (line 13))\n",
            "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting Babel==2.14.0 (from -r requirements.txt (line 14))\n",
            "  Downloading Babel-2.14.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting backoff==2.2.1 (from -r requirements.txt (line 15))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting bcrypt==4.1.2 (from -r requirements.txt (line 16))\n",
            "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4==4.12.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.12.3)\n",
            "Requirement already satisfied: bleach==6.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (6.1.0)\n",
            "Collecting blinker==1.7.0 (from -r requirements.txt (line 19))\n",
            "  Downloading blinker-1.7.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting build==1.1.1 (from -r requirements.txt (line 20))\n",
            "  Downloading build-1.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting cachetools==5.3.3 (from -r requirements.txt (line 21))\n",
            "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting certifi==2024.2.2 (from -r requirements.txt (line 22))\n",
            "  Downloading certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting cffi==1.16.0 (from -r requirements.txt (line 23))\n",
            "  Downloading cffi-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: charset-normalizer==3.3.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (3.3.2)\n",
            "Collecting chroma-hnswlib==0.7.3 (from -r requirements.txt (line 25))\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Requirement already satisfied: click==8.1.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (8.1.7)\n",
            "Collecting coloredlogs==15.0.1 (from -r requirements.txt (line 27))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting comm==0.2.1 (from -r requirements.txt (line 28))\n",
            "  Downloading comm-0.2.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting dataclasses-json==0.6.4 (from -r requirements.txt (line 29))\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting debugpy==1.8.1 (from -r requirements.txt (line 30))\n",
            "  Downloading debugpy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting decorator==5.1.1 (from -r requirements.txt (line 31))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: defusedxml==0.7.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (0.7.1)\n",
            "Collecting Deprecated==1.2.14 (from -r requirements.txt (line 33))\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting distro==1.9.0 (from -r requirements.txt (line 34))\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting executing==2.0.1 (from -r requirements.txt (line 35))\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting fastapi==0.110.0 (from -r requirements.txt (line 36))\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting fastjsonschema==2.19.1 (from -r requirements.txt (line 37))\n",
            "  Downloading fastjsonschema-2.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting filelock==3.13.1 (from -r requirements.txt (line 38))\n",
            "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting flatbuffers==24.3.7 (from -r requirements.txt (line 39))\n",
            "  Downloading flatbuffers-24.3.7-py2.py3-none-any.whl.metadata (849 bytes)\n",
            "Collecting fqdn==1.5.1 (from -r requirements.txt (line 40))\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: frozenlist==1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 41)) (1.4.1)\n",
            "Collecting fsspec==2024.2.0 (from -r requirements.txt (line 42))\n",
            "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting gitdb==4.0.11 (from -r requirements.txt (line 43))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting GitPython==3.1.42 (from -r requirements.txt (line 44))\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting google-auth==2.29.0 (from -r requirements.txt (line 45))\n",
            "  Downloading google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting googleapis-common-protos==1.63.0 (from -r requirements.txt (line 46))\n",
            "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting grpcio==1.62.1 (from -r requirements.txt (line 47))\n",
            "  Downloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting h11==0.14.0 (from -r requirements.txt (line 48))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting httpcore==1.0.4 (from -r requirements.txt (line 49))\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting httptools==0.6.1 (from -r requirements.txt (line 50))\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting httpx==0.27.0 (from -r requirements.txt (line 51))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting huggingface-hub==0.21.4 (from -r requirements.txt (line 52))\n",
            "  Downloading huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting humanfriendly==10.0 (from -r requirements.txt (line 53))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting idna==3.6 (from -r requirements.txt (line 54))\n",
            "  Downloading idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting importlib-metadata==6.11.0 (from -r requirements.txt (line 55))\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting importlib_resources==6.4.0 (from -r requirements.txt (line 56))\n",
            "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting ipykernel==6.29.3 (from -r requirements.txt (line 57))\n",
            "  Downloading ipykernel-6.29.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting ipython==8.22.2 (from -r requirements.txt (line 58))\n",
            "  Downloading ipython-8.22.2-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting ipywidgets==8.1.2 (from -r requirements.txt (line 59))\n",
            "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting iso-639==0.4.5 (from -r requirements.txt (line 60))\n",
            "  Downloading iso-639-0.4.5.tar.gz (167 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.4/167.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting isoduration==20.11.0 (from -r requirements.txt (line 61))\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jedi==0.19.1 (from -r requirements.txt (line 62))\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting Jinja2==3.1.3 (from -r requirements.txt (line 63))\n",
            "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting json5==0.9.22 (from -r requirements.txt (line 64))\n",
            "  Downloading json5-0.9.22-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting jsonpatch==1.33 (from -r requirements.txt (line 65))\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting jsonpointer==2.4 (from -r requirements.txt (line 66))\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting jsonschema==4.21.1 (from -r requirements.txt (line 67))\n",
            "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: jsonschema-specifications==2023.12.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 68)) (2023.12.1)\n",
            "Collecting jupyter==1.0.0 (from -r requirements.txt (line 69))\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
            "Collecting jupyter-console==6.6.3 (from -r requirements.txt (line 70))\n",
            "  Downloading jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-events==0.9.0 (from -r requirements.txt (line 71))\n",
            "  Downloading jupyter_events-0.9.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jupyter-lsp==2.2.4 (from -r requirements.txt (line 72))\n",
            "  Downloading jupyter_lsp-2.2.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter_client==8.6.0 (from -r requirements.txt (line 73))\n",
            "  Downloading jupyter_client-8.6.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter_core==5.7.1 (from -r requirements.txt (line 74))\n",
            "  Downloading jupyter_core-5.7.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting jupyter_server==2.13.0 (from -r requirements.txt (line 75))\n",
            "  Downloading jupyter_server-2.13.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyter_server_terminals==0.5.2 (from -r requirements.txt (line 76))\n",
            "  Downloading jupyter_server_terminals-0.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting jupyterlab==4.1.4 (from -r requirements.txt (line 77))\n",
            "  Downloading jupyterlab-4.1.4-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: jupyterlab_pygments==0.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 78)) (0.3.0)\n",
            "Collecting jupyterlab_server==2.25.3 (from -r requirements.txt (line 79))\n",
            "  Downloading jupyterlab_server-2.25.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jupyterlab_widgets==3.0.10 (from -r requirements.txt (line 80))\n",
            "  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting kubernetes==29.0.0 (from -r requirements.txt (line 81))\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain==0.1.13 (from -r requirements.txt (line 82))\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-community==0.0.29 (from -r requirements.txt (line 83))\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting langchain-core==0.1.33 (from -r requirements.txt (line 84))\n",
            "  Downloading langchain_core-0.1.33-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting langchain-experimental==0.0.54 (from -r requirements.txt (line 85))\n",
            "  Downloading langchain_experimental-0.0.54-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting langchain-openai==0.0.8 (from -r requirements.txt (line 86))\n",
            "  Downloading langchain_openai-0.0.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting langchain-pinecone==0.0.3 (from -r requirements.txt (line 87))\n",
            "  Downloading langchain_pinecone-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting langchain-text-splitters==0.0.1 (from -r requirements.txt (line 88))\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting langsmith==0.1.23 (from -r requirements.txt (line 89))\n",
            "  Downloading langsmith-0.1.23-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting lark==1.1.9 (from -r requirements.txt (line 90))\n",
            "  Downloading lark-1.1.9-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: markdown-it-py==3.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 91)) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe==2.1.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 92)) (2.1.5)\n",
            "Collecting marshmallow==3.21.1 (from -r requirements.txt (line 93))\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting matplotlib-inline==0.1.6 (from -r requirements.txt (line 94))\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 95)) (0.1.2)\n",
            "Collecting mistune==3.0.2 (from -r requirements.txt (line 96))\n",
            "  Downloading mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3==4.1.0 (from -r requirements.txt (line 97))\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting monotonic==1.6 (from -r requirements.txt (line 98))\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 99)) (1.3.0)\n",
            "Requirement already satisfied: multidict==6.0.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 100)) (6.0.5)\n",
            "Collecting mypy-extensions==1.0.0 (from -r requirements.txt (line 101))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting nbclient==0.9.0 (from -r requirements.txt (line 102))\n",
            "  Downloading nbclient-0.9.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting nbconvert==7.16.2 (from -r requirements.txt (line 103))\n",
            "  Downloading nbconvert-7.16.2-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting nbformat==5.9.2 (from -r requirements.txt (line 104))\n",
            "  Downloading nbformat-5.9.2-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting neo4j==5.18.0 (from -r requirements.txt (line 105))\n",
            "  Downloading neo4j-5.18.0.tar.gz (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.0/198.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 106)) (1.6.0)\n",
            "Collecting notebook==7.1.1 (from -r requirements.txt (line 107))\n",
            "  Downloading notebook-7.1.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: notebook_shim==0.2.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 108)) (0.2.4)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 109)) (1.26.4)\n",
            "Requirement already satisfied: oauthlib==3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 110)) (3.2.2)\n",
            "Collecting onnxruntime==1.17.1 (from -r requirements.txt (line 111))\n",
            "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting openai==1.13.3 (from -r requirements.txt (line 112))\n",
            "  Downloading openai-1.13.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting opentelemetry-api==1.23.0 (from -r requirements.txt (line 113))\n",
            "  Downloading opentelemetry_api-1.23.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.23.0 (from -r requirements.txt (line 114))\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc==1.23.0 (from -r requirements.txt (line 115))\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation==0.44b0 (from -r requirements.txt (line 116))\n",
            "  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.44b0 (from -r requirements.txt (line 117))\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi==0.44b0 (from -r requirements.txt (line 118))\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-proto==1.23.0 (from -r requirements.txt (line 119))\n",
            "  Downloading opentelemetry_proto-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-sdk==1.23.0 (from -r requirements.txt (line 120))\n",
            "  Downloading opentelemetry_sdk-1.23.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.44b0 (from -r requirements.txt (line 121))\n",
            "  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-util-http==0.44b0 (from -r requirements.txt (line 122))\n",
            "  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting orjson==3.9.15 (from -r requirements.txt (line 123))\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting overrides==7.7.0 (from -r requirements.txt (line 124))\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting packaging==23.2 (from -r requirements.txt (line 125))\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pandas==2.2.1 (from -r requirements.txt (line 126))\n",
            "  Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: pandocfilters==1.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 127)) (1.5.1)\n",
            "Collecting parso==0.8.3 (from -r requirements.txt (line 128))\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: pexpect==4.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 129)) (4.9.0)\n",
            "Collecting pillow==10.2.0 (from -r requirements.txt (line 130))\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Collecting pinecone-client==3.1.0 (from -r requirements.txt (line 131))\n",
            "  Downloading pinecone_client-3.1.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting platformdirs==4.2.0 (from -r requirements.txt (line 132))\n",
            "  Downloading platformdirs-4.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting posthog==3.5.0 (from -r requirements.txt (line 133))\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: prometheus_client==0.20.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 134)) (0.20.0)\n",
            "Collecting prompt-toolkit==3.0.43 (from -r requirements.txt (line 135))\n",
            "  Downloading prompt_toolkit-3.0.43-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting protobuf==4.25.3 (from -r requirements.txt (line 136))\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting psutil==5.9.8 (from -r requirements.txt (line 137))\n",
            "  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 138)) (0.7.0)\n",
            "Collecting pulsar-client==3.4.0 (from -r requirements.txt (line 139))\n",
            "  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting pure-eval==0.2.2 (from -r requirements.txt (line 140))\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pyarrow==15.0.2 (from -r requirements.txt (line 141))\n",
            "  Downloading pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pyasn1==0.5.1 (from -r requirements.txt (line 142))\n",
            "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting pyasn1-modules==0.3.0 (from -r requirements.txt (line 143))\n",
            "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting pycparser==2.21 (from -r requirements.txt (line 144))\n",
            "  Downloading pycparser-2.21-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pydantic==2.6.3 (from -r requirements.txt (line 145))\n",
            "  Downloading pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic_core==2.16.3 (from -r requirements.txt (line 146))\n",
            "  Downloading pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pydeck==0.8.1b0 (from -r requirements.txt (line 147))\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting Pygments==2.17.2 (from -r requirements.txt (line 148))\n",
            "  Downloading pygments-2.17.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting PyPika==0.48.9 (from -r requirements.txt (line 149))\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyproject_hooks==1.0.0 (from -r requirements.txt (line 150))\n",
            "  Downloading pyproject_hooks-1.0.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting python-dateutil==2.9.0.post0 (from -r requirements.txt (line 151))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting python-dotenv==1.0.1 (from -r requirements.txt (line 152))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting python-json-logger==2.0.7 (from -r requirements.txt (line 153))\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pytz==2024.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 154)) (2024.1)\n",
            "Collecting PyYAML==6.0.1 (from -r requirements.txt (line 155))\n",
            "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting pyzmq==25.1.2 (from -r requirements.txt (line 156))\n",
            "  Downloading pyzmq-25.1.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting qtconsole==5.5.1 (from -r requirements.txt (line 157))\n",
            "  Downloading qtconsole-5.5.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting QtPy==2.4.1 (from -r requirements.txt (line 158))\n",
            "  Downloading QtPy-2.4.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting referencing==0.33.0 (from -r requirements.txt (line 159))\n",
            "  Downloading referencing-0.33.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting regex==2023.12.25 (from -r requirements.txt (line 160))\n",
            "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests==2.31.0 (from -r requirements.txt (line 161))\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting requests-oauthlib==1.4.0 (from -r requirements.txt (line 162))\n",
            "  Downloading requests_oauthlib-1.4.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting rfc3339-validator==0.1.4 (from -r requirements.txt (line 163))\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator==0.1.1 (from -r requirements.txt (line 164))\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting rich==13.7.1 (from -r requirements.txt (line 165))\n",
            "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rpds-py==0.18.0 (from -r requirements.txt (line 166))\n",
            "  Downloading rpds_py-0.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: rsa==4.9 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 167)) (4.9)\n",
            "Collecting safetensors==0.4.2 (from -r requirements.txt (line 168))\n",
            "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting Send2Trash==1.8.2 (from -r requirements.txt (line 169))\n",
            "  Downloading Send2Trash-1.8.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting setuptools==68.2.2 (from -r requirements.txt (line 170))\n",
            "  Downloading setuptools-68.2.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 171)) (1.16.0)\n",
            "Collecting smmap==5.0.1 (from -r requirements.txt (line 172))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 173)) (1.3.1)\n",
            "Collecting soupsieve==2.5 (from -r requirements.txt (line 174))\n",
            "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting SQLAlchemy==2.0.28 (from -r requirements.txt (line 175))\n",
            "  Downloading SQLAlchemy-2.0.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting stack-data==0.6.3 (from -r requirements.txt (line 176))\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting starlette==0.36.3 (from -r requirements.txt (line 177))\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting streamlit==1.32.2 (from -r requirements.txt (line 178))\n",
            "  Downloading streamlit-1.32.2-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting sympy==1.12 (from -r requirements.txt (line 179))\n",
            "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 180)) (0.9.0)\n",
            "Collecting tenacity==8.2.3 (from -r requirements.txt (line 181))\n",
            "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting terminado==0.18.0 (from -r requirements.txt (line 182))\n",
            "  Downloading terminado-0.18.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting tiktoken==0.6.0 (from -r requirements.txt (line 183))\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting tinycss2==1.2.1 (from -r requirements.txt (line 184))\n",
            "  Downloading tinycss2-1.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting tokenizers==0.15.2 (from -r requirements.txt (line 185))\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 186)) (0.10.2)\n",
            "Requirement already satisfied: toolz==0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 187)) (0.12.1)\n",
            "Collecting tornado==6.4 (from -r requirements.txt (line 188))\n",
            "  Downloading tornado-6.4-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting tqdm==4.66.2 (from -r requirements.txt (line 189))\n",
            "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting traitlets==5.14.1 (from -r requirements.txt (line 190))\n",
            "  Downloading traitlets-5.14.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting transformers==4.38.2 (from -r requirements.txt (line 191))\n",
            "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typer==0.9.0 (from -r requirements.txt (line 192))\n",
            "  Downloading typer-0.9.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting types-python-dateutil==2.8.19.20240106 (from -r requirements.txt (line 193))\n",
            "  Downloading types_python_dateutil-2.8.19.20240106-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting typing-inspect==0.9.0 (from -r requirements.txt (line 194))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting typing_extensions==4.10.0 (from -r requirements.txt (line 195))\n",
            "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: tzdata==2024.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 196)) (2024.1)\n",
            "Collecting uri-template==1.3.0 (from -r requirements.txt (line 197))\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting urllib3==2.2.1 (from -r requirements.txt (line 198))\n",
            "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting uvicorn==0.29.0 (from -r requirements.txt (line 199))\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting uvloop==0.19.0 (from -r requirements.txt (line 200))\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles==0.21.0 (from -r requirements.txt (line 201))\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: wcwidth==0.2.13 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 202)) (0.2.13)\n",
            "Collecting webcolors==1.13 (from -r requirements.txt (line 203))\n",
            "  Downloading webcolors-1.13-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 204)) (0.5.1)\n",
            "Collecting websocket-client==1.7.0 (from -r requirements.txt (line 205))\n",
            "  Downloading websocket_client-1.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting websockets==12.0 (from -r requirements.txt (line 206))\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting wheel==0.41.2 (from -r requirements.txt (line 207))\n",
            "  Downloading wheel-0.41.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting widgetsnbextension==4.0.10 (from -r requirements.txt (line 208))\n",
            "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: wrapt==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 209)) (1.16.0)\n",
            "Requirement already satisfied: yarl==1.9.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 210)) (1.9.4)\n",
            "Collecting zipp==3.18.1 (from -r requirements.txt (line 211))\n",
            "  Downloading zipp-3.18.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.3->-r requirements.txt (line 1)) (4.0.3)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio==4.3.0->-r requirements.txt (line 5)) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build==1.1.1->-r requirements.txt (line 20)) (2.0.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy==2.0.28->-r requirements.txt (line 175)) (3.0.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit==1.32.2->-r requirements.txt (line 178))\n",
            "  Downloading watchdog-5.0.0-py3-none-manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'requests-oauthlib' candidate (version 1.4.0 at https://files.pythonhosted.org/packages/db/3a/457f30ab4e80b0e978686ccd43f17309e9fdc242d8619491a9156a19fda5/requests_oauthlib-1.4.0-py2.py3-none-any.whl (from https://pypi.org/simple/requests-oauthlib/) (requires-python:>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*))\n",
            "Reason for being yanked: Incorrect package metadata\u001b[0m\u001b[33m\n",
            "\u001b[0mDownloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading altair-5.2.0-py3-none-any.whl (996 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.9/996.9 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Downloading anyio-4.3.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appnope-0.1.4-py2.py3-none-any.whl (4.3 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.0-py3-none-any.whl (23 kB)\n",
            "Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
            "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Babel-2.14.0-py3-none-any.whl (11.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blinker-1.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading build-1.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
            "Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cffi-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.9/443.9 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.1-py3-none-any.whl (7.2 kB)\n",
            "Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading debugpy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastjsonschema-2.19.1-py3-none-any.whl (23 kB)\n",
            "Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Downloading flatbuffers-24.3.7-py2.py3-none-any.whl (26 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
            "Downloading ipykernel-6.29.3-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.1/117.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipython-8.22.2-py3-none-any.whl (811 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.0/812.0 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Downloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.9.22-py3-none-any.whl (29 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading jupyter_events-0.9.0-py3-none-any.whl (18 kB)\n",
            "Downloading jupyter_lsp-2.2.4-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-8.6.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_core-5.7.1-py3-none-any.whl (28 kB)\n",
            "Downloading jupyter_server-2.13.0-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.2/383.2 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server_terminals-0.5.2-py3-none-any.whl (13 kB)\n",
            "Downloading jupyterlab-4.1.4-py3-none-any.whl (11.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.25.3-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.0/215.0 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.0.54-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.0.8-py3-none-any.whl (32 kB)\n",
            "Downloading langchain_pinecone-0.0.3-py3-none-any.whl (8.3 kB)\n",
            "Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Downloading langsmith-0.1.23-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lark-1.1.9-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Downloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading nbclient-0.9.0-py3-none-any.whl (24 kB)\n",
            "Downloading nbconvert-7.16.2-py3-none-any.whl (257 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.3/257.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nbformat-5.9.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.6/77.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading notebook-7.1.1-py3-none-any.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.23.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl (28 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl (14 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl (11 kB)\n",
            "Downloading opentelemetry_proto-1.23.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.23.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl (36 kB)\n",
            "Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m886.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_client-3.1.0-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.0/211.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading platformdirs-4.2.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prompt_toolkit-3.0.43-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.1/386.1 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Downloading pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.2/395.2 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyzmq-25.1.2-cp310-cp310-manylinux_2_28_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qtconsole-5.5.1-py3-none-any.whl (123 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading referencing-0.33.0-py3-none-any.whl (26 kB)\n",
            "Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_oauthlib-1.4.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rpds_py-0.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Send2Trash-1.8.2-py3-none-any.whl (18 kB)\n",
            "Downloading setuptools-68.2.2-py3-none-any.whl (807 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
            "Downloading SQLAlchemy-2.0.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.32.2-py2.py3-none-any.whl (8.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
            "Downloading terminado-0.18.0-py3-none-any.whl (14 kB)\n",
            "Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
            "Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tornado-6.4-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.4/435.4 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading traitlets-5.14.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.8.19.20240106-py3-none-any.whl (9.7 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webcolors-1.13-py3-none-any.whl (14 kB)\n",
            "Downloading websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.41.2-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zipp-3.18.1-py3-none-any.whl (8.2 kB)\n",
            "Downloading watchdog-5.0.0-py3-none-manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: iso-639, neo4j, PyPika\n",
            "  Building wheel for iso-639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iso-639: filename=iso_639-0.4.5-py3-none-any.whl size=168840 sha256=3a827f57a93dd4e2982fde5ec7648aa48c3fb34f127cee766106c5ced3dbb5e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/78/cc/5478ca3b1c3f602eae6f8cdbd78f909c0a0bfa0bbcb5c7771f\n",
            "  Building wheel for neo4j (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neo4j: filename=neo4j-5.18.0-py3-none-any.whl size=273862 sha256=9b3e6b0235085ce32d392f83f94d3860119757a1f872f6d99463bcb0321d3944\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/e1/a0/dd7c19192f5383ff57d02a6c126cbfe4b7b2ae82f70c6994ce\n",
            "  Building wheel for PyPika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53726 sha256=e0ada5510bee9e8ad94f8172ded68b14252d02cf809233cf74a2332c0744685c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built iso-639 neo4j PyPika\n",
            "Installing collected packages: PyPika, pure-eval, monotonic, mmh3, iso-639, flatbuffers, fastjsonschema, zipp, widgetsnbextension, wheel, websockets, websocket-client, webcolors, watchdog, uvloop, urllib3, uri-template, typing_extensions, types-python-dateutil, traitlets, tqdm, tornado, tinycss2, tenacity, sympy, soupsieve, smmap, setuptools, Send2Trash, safetensors, rpds-py, rfc3986-validator, rfc3339-validator, regex, pyzmq, PyYAML, python-json-logger, python-dotenv, python-dateutil, pyproject_hooks, Pygments, pycparser, pyasn1, pyarrow, psutil, protobuf, prompt-toolkit, platformdirs, pillow, parso, packaging, overrides, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, neo4j, mypy-extensions, mistune, lark, jupyterlab_widgets, jsonpointer, json5, Jinja2, importlib_resources, idna, humanfriendly, httptools, h11, grpcio, fsspec, fqdn, filelock, executing, distro, Deprecated, decorator, debugpy, chroma-hnswlib, certifi, cachetools, blinker, bcrypt, backoff, Babel, attrs, asttokens, appnope, annotated-types, uvicorn, typing-inspect, typer, terminado, stack-data, SQLAlchemy, rich, requests, referencing, QtPy, pydeck, pydantic_core, pyasn1-modules, pulsar-client, pinecone-client, pandas, opentelemetry-proto, matplotlib-inline, marshmallow, jupyter_core, jsonpatch, jedi, importlib-metadata, httpcore, googleapis-common-protos, gitdb, comm, coloredlogs, cffi, build, async-lru, asgiref, arrow, anyio, watchfiles, tiktoken, starlette, requests-oauthlib, pydantic, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, jupyter_server_terminals, jupyter_client, isoduration, ipython, huggingface-hub, httpx, google-auth, GitPython, dataclasses-json, aiohttp, tokenizers, opentelemetry-sdk, opentelemetry-instrumentation, openai, langsmith, kubernetes, jsonschema, ipywidgets, ipykernel, fastapi, transformers, qtconsole, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, nbformat, langchain-core, jupyter-console, altair, streamlit, opentelemetry-instrumentation-fastapi, nbclient, langchain-text-splitters, langchain-pinecone, langchain-openai, langchain-community, jupyter-events, nbconvert, langchain, langchain-experimental, jupyter_server, jupyterlab_server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 24.3.25\n",
            "    Uninstalling flatbuffers-24.3.25:\n",
            "      Successfully uninstalled flatbuffers-24.3.25\n",
            "  Attempting uninstall: fastjsonschema\n",
            "    Found existing installation: fastjsonschema 2.20.0\n",
            "    Uninstalling fastjsonschema-2.20.0:\n",
            "      Successfully uninstalled fastjsonschema-2.20.0\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.20.1\n",
            "    Uninstalling zipp-3.20.1:\n",
            "      Successfully uninstalled zipp-3.20.1\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.8\n",
            "    Uninstalling widgetsnbextension-3.6.8:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.8\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.44.0\n",
            "    Uninstalling wheel-0.44.0:\n",
            "      Successfully uninstalled wheel-0.44.0\n",
            "  Attempting uninstall: websocket-client\n",
            "    Found existing installation: websocket-client 1.8.0\n",
            "    Uninstalling websocket-client-1.8.0:\n",
            "      Successfully uninstalled websocket-client-1.8.0\n",
            "  Attempting uninstall: webcolors\n",
            "    Found existing installation: webcolors 24.8.0\n",
            "    Uninstalling webcolors-24.8.0:\n",
            "      Successfully uninstalled webcolors-24.8.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.7.1\n",
            "    Uninstalling traitlets-5.7.1:\n",
            "      Successfully uninstalled traitlets-5.7.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.5\n",
            "    Uninstalling tqdm-4.66.5:\n",
            "      Successfully uninstalled tqdm-4.66.5\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 6.3.3\n",
            "    Uninstalling tornado-6.3.3:\n",
            "      Successfully uninstalled tornado-6.3.3\n",
            "  Attempting uninstall: tinycss2\n",
            "    Found existing installation: tinycss2 1.3.0\n",
            "    Uninstalling tinycss2-1.3.0:\n",
            "      Successfully uninstalled tinycss2-1.3.0\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.2\n",
            "    Uninstalling sympy-1.13.2:\n",
            "      Successfully uninstalled sympy-1.13.2\n",
            "  Attempting uninstall: soupsieve\n",
            "    Found existing installation: soupsieve 2.6\n",
            "    Uninstalling soupsieve-2.6:\n",
            "      Successfully uninstalled soupsieve-2.6\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 71.0.4\n",
            "    Uninstalling setuptools-71.0.4:\n",
            "      Successfully uninstalled setuptools-71.0.4\n",
            "  Attempting uninstall: Send2Trash\n",
            "    Found existing installation: Send2Trash 1.8.3\n",
            "    Uninstalling Send2Trash-1.8.3:\n",
            "      Successfully uninstalled Send2Trash-1.8.3\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.4.4\n",
            "    Uninstalling safetensors-0.4.4:\n",
            "      Successfully uninstalled safetensors-0.4.4\n",
            "  Attempting uninstall: rpds-py\n",
            "    Found existing installation: rpds-py 0.20.0\n",
            "    Uninstalling rpds-py-0.20.0:\n",
            "      Successfully uninstalled rpds-py-0.20.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.5.15\n",
            "    Uninstalling regex-2024.5.15:\n",
            "      Successfully uninstalled regex-2024.5.15\n",
            "  Attempting uninstall: pyzmq\n",
            "    Found existing installation: pyzmq 24.0.1\n",
            "    Uninstalling pyzmq-24.0.1:\n",
            "      Successfully uninstalled pyzmq-24.0.1\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pyproject_hooks\n",
            "    Found existing installation: pyproject_hooks 1.1.0\n",
            "    Uninstalling pyproject_hooks-1.1.0:\n",
            "      Successfully uninstalled pyproject_hooks-1.1.0\n",
            "  Attempting uninstall: Pygments\n",
            "    Found existing installation: Pygments 2.16.1\n",
            "    Uninstalling Pygments-2.16.1:\n",
            "      Successfully uninstalled Pygments-2.16.1\n",
            "  Attempting uninstall: pycparser\n",
            "    Found existing installation: pycparser 2.22\n",
            "    Uninstalling pycparser-2.22:\n",
            "      Successfully uninstalled pycparser-2.22\n",
            "  Attempting uninstall: pyasn1\n",
            "    Found existing installation: pyasn1 0.6.0\n",
            "    Uninstalling pyasn1-0.6.0:\n",
            "      Successfully uninstalled pyasn1-0.6.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt_toolkit 3.0.47\n",
            "    Uninstalling prompt_toolkit-3.0.47:\n",
            "      Successfully uninstalled prompt_toolkit-3.0.47\n",
            "  Attempting uninstall: platformdirs\n",
            "    Found existing installation: platformdirs 4.2.2\n",
            "    Uninstalling platformdirs-4.2.2:\n",
            "      Successfully uninstalled platformdirs-4.2.2\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: parso\n",
            "    Found existing installation: parso 0.8.4\n",
            "    Uninstalling parso-0.8.4:\n",
            "      Successfully uninstalled parso-0.8.4\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "  Attempting uninstall: mistune\n",
            "    Found existing installation: mistune 0.8.4\n",
            "    Uninstalling mistune-0.8.4:\n",
            "      Successfully uninstalled mistune-0.8.4\n",
            "  Attempting uninstall: jupyterlab_widgets\n",
            "    Found existing installation: jupyterlab_widgets 3.0.13\n",
            "    Uninstalling jupyterlab_widgets-3.0.13:\n",
            "      Successfully uninstalled jupyterlab_widgets-3.0.13\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 3.1.4\n",
            "    Uninstalling Jinja2-3.1.4:\n",
            "      Successfully uninstalled Jinja2-3.1.4\n",
            "  Attempting uninstall: importlib_resources\n",
            "    Found existing installation: importlib_resources 6.4.4\n",
            "    Uninstalling importlib_resources-6.4.4:\n",
            "      Successfully uninstalled importlib_resources-6.4.4\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.8\n",
            "    Uninstalling idna-3.8:\n",
            "      Successfully uninstalled idna-3.8\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.64.1\n",
            "    Uninstalling grpcio-1.64.1:\n",
            "      Successfully uninstalled grpcio-1.64.1\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.15.4\n",
            "    Uninstalling filelock-3.15.4:\n",
            "      Successfully uninstalled filelock-3.15.4\n",
            "  Attempting uninstall: distro\n",
            "    Found existing installation: distro 1.7.0\n",
            "    Uninstalling distro-1.7.0:\n",
            "      Successfully uninstalled distro-1.7.0\n",
            "  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 4.4.2\n",
            "    Uninstalling decorator-4.4.2:\n",
            "      Successfully uninstalled decorator-4.4.2\n",
            "  Attempting uninstall: debugpy\n",
            "    Found existing installation: debugpy 1.6.6\n",
            "    Uninstalling debugpy-1.6.6:\n",
            "      Successfully uninstalled debugpy-1.6.6\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.7.4\n",
            "    Uninstalling certifi-2024.7.4:\n",
            "      Successfully uninstalled certifi-2024.7.4\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.0\n",
            "    Uninstalling cachetools-5.5.0:\n",
            "      Successfully uninstalled cachetools-5.5.0\n",
            "  Attempting uninstall: blinker\n",
            "    Found existing installation: blinker 1.4\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1muninstall-distutils-installed-package\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Cannot uninstall blinker 1.4\n",
            "\u001b[31m╰─>\u001b[0m It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Solicitação de chaves das APIs**"
      ],
      "metadata": {
        "id": "t_Ri2iEohLLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "TMBD_API_KEY = getpass(\"Digite a chave do TMDB: \")\n",
        "PINECONE_KEY = getpass(\"Digite a chave do Pinecone: \")\n",
        "OPENAI_API_KEY = getpass(\"Digite a chave da OpenAI: \")\n",
        "PINECONE_INDEX_NAME = \"seminario\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXdWROmklbrQ",
        "outputId": "b007911c-3496-4850-df3d-919ded3a4e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Digite a chave do TMDB: ··········\n",
            "Digite a chave do Pinecone: ··········\n",
            "Digite a chave da OpenAI: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **utils.py**"
      ],
      "metadata": {
        "id": "87rcDqBGgT3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O arquivo utils.py contém algumas funções auxiliares que têm como objetivo consumir a API do TMDB, buscando os IDs dos filmes e os dados sobre eles e para escrever os arquivos CSV.\n",
        "\n",
        "As seguintes informações foram extraídas sobre cada filme:\n",
        "\n",
        "- Title\n",
        "- Runtime (minutes)\n",
        "- Language\n",
        "- Overview\n",
        "- Release Year\n",
        "- Genre\n",
        "- Keywords describing the film\n",
        "- Actors\n",
        "- Directors\n",
        "- Places to stream\n",
        "- Places to buy\n",
        "- Places to rent\n",
        "- List of Production Companies"
      ],
      "metadata": {
        "id": "jyPx9UDK7MhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "import csv\n",
        "import time\n",
        "from iso639 import languages\n",
        "\n",
        "def get_id_list(api_key, year, max_retries=5):\n",
        "    \"\"\"\n",
        "    Function to get list of IDs for all films made in {year}.\n",
        "\n",
        "    parameters:\n",
        "    api_key (str): API key for TMDB\n",
        "    year (int): Year of interest\n",
        "\n",
        "    returns:\n",
        "    list of str: List of all movie ids in {year}\n",
        "    \"\"\"\n",
        "    url = f'https://api.themoviedb.org/3/discover/movie?api_key={api_key}&primary_release_year={year}&include_video=false&language=en-US&sort_by=popularity.desc'\n",
        "\n",
        "    movie_ids = []\n",
        "\n",
        "    total_pages = 5  # 5 pages of ids = 100 movies\n",
        "    for page in range(1, total_pages + 1):\n",
        "        for i in range(max_retries):\n",
        "            response = requests.get(url + f'&page={page}')\n",
        "            if response.status_code == 429:\n",
        "                # If the response was a 429, wait and then try again\n",
        "                print(\n",
        "                    f\"Request limit reached. Waiting and retrying ({i+1}/{max_retries})\")\n",
        "                time.sleep(2 ** i)  # Exponential backoff\n",
        "\n",
        "            else:\n",
        "                # If the response was not a 429, continue\n",
        "                response_dict = response.json()\n",
        "                for film in response_dict['results']:\n",
        "                    movie_ids.append(str(film['id']))\n",
        "                break\n",
        "\n",
        "    return movie_ids\n",
        "\n",
        "\n",
        "def get_data(API_key, Movie_ID, max_retries=5):\n",
        "    \"\"\"\n",
        "    Function to pull details of your film of interest in JSON format.\n",
        "\n",
        "    parameters:\n",
        "    API_key (str): Your API key for TMBD\n",
        "    Movie_ID (str): TMDB id for film of interest\n",
        "\n",
        "    returns:\n",
        "    dict: JSON formatted dictionary containing all details of your film of\n",
        "    interest\n",
        "    \"\"\"\n",
        "\n",
        "    query = 'https://api.themoviedb.org/3/movie/' + Movie_ID + \\\n",
        "        '?api_key='+API_key + '&append_to_response=keywords,' + \\\n",
        "            'watch/providers,credits&language=en-US'\n",
        "    for i in range(max_retries):\n",
        "        response = requests.get(query)\n",
        "        if response.status_code == 429:\n",
        "            # If the response was a 429, wait and then try again\n",
        "            print(\n",
        "                f\"Request limit reached. Waiting and retrying ({i+1}/{max_retries})\")\n",
        "            time.sleep(2 ** i)  # Exponential backoff\n",
        "        else:\n",
        "            response_dict = response.json()\n",
        "            return response_dict\n",
        "\n",
        "\n",
        "def write_file(filename, data):\n",
        "    \"\"\"\n",
        "    Appends a row to a csv file titled 'filename', if the\n",
        "    movie belongs to a collection. The row contains the name of the\n",
        "    movie in the first column and the name of the collection in the\n",
        "    second column. Adds nothing if the film is not part of the collection.\n",
        "\n",
        "    parameters:\n",
        "    filename (str): Name of file you desire for the csv\n",
        "    dict (dict): Python dictionary with JSON formatted details of film\n",
        "\n",
        "    returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    csvFile = open(filename, 'a')\n",
        "    csvwriter = csv.writer(csvFile)\n",
        "    # unpack the result to access the \"collection name\" element\n",
        "    title = data['title']\n",
        "    runtime = data['runtime']\n",
        "    language_code = data['original_language']\n",
        "    release_date = data['release_date']\n",
        "    overview = data['overview']\n",
        "    all_genres = data['genres']\n",
        "    prod_companies = data['production_companies']\n",
        "\n",
        "    # Parsing release date\n",
        "    release_year = release_date.split('-')[0]\n",
        "\n",
        "    # Converting language\n",
        "    try:\n",
        "        language = languages.get(alpha2=language_code).name\n",
        "    except KeyError:\n",
        "        language = 'Unknown'\n",
        "\n",
        "    # Parsing genres\n",
        "    genre_str = \"\"\n",
        "    for genre in all_genres:\n",
        "        genre_str += genre['name'] + \", \"\n",
        "    genre_str = genre_str[:-2]\n",
        "\n",
        "    # Parsing keywords (remove non-English words)\n",
        "    all_keywords = data['keywords']['keywords']\n",
        "    keyword_str = \"\"\n",
        "    for keyword in all_keywords:\n",
        "        if is_english(keyword['name']):\n",
        "            keyword_str += keyword['name'] + \", \"\n",
        "    if keyword_str == \"\":\n",
        "        keyword_str = \"None\"\n",
        "    else:\n",
        "        keyword_str = keyword_str[:-2]\n",
        "\n",
        "    # Parsing watch providers\n",
        "    watch_providers = data['watch/providers']['results']\n",
        "    stream_str, buy_str, rent_str = \"\", \"\", \"\"\n",
        "    if 'US' in watch_providers:\n",
        "        watch_providers = watch_providers['US']\n",
        "        provider_strings = ['flatrate', 'buy', 'rent']\n",
        "        for string in provider_strings:\n",
        "            if string not in watch_providers:\n",
        "                continue\n",
        "\n",
        "            _str = \"\"\n",
        "\n",
        "            for element in watch_providers[string]:\n",
        "                _str += element['provider_name'] + \", \"\n",
        "            _str = _str[:-2] + \" \"\n",
        "\n",
        "            if string == 'flatrate':\n",
        "                stream_str += _str\n",
        "            elif string == 'buy':\n",
        "                buy_str += _str\n",
        "            else:\n",
        "                rent_str += _str\n",
        "\n",
        "    credits = data['credits']\n",
        "    actor_list, director_list = [], []\n",
        "\n",
        "    # Parsing cast\n",
        "    cast = credits['cast']\n",
        "    NUM_ACTORS = 5\n",
        "    for member in cast[:NUM_ACTORS]:\n",
        "        actor_list.append(member[\"name\"])\n",
        "\n",
        "    # Parsing crew\n",
        "    crew = credits['crew']\n",
        "    for member in crew:\n",
        "        if member['job'] == 'Director':\n",
        "            director_list.append(member[\"name\"])\n",
        "\n",
        "    actor_str = ', '.join(list(set(actor_list)))\n",
        "    director_str = ', '.join(list(set(director_list)))\n",
        "\n",
        "    # Parsing production companies\n",
        "    prod_str = \"\"\n",
        "    for company in prod_companies:\n",
        "        prod_str += company['name'] + \", \"\n",
        "    prod_str = prod_str[:-2]\n",
        "\n",
        "    # # Adding Wikipedia summaries if available\n",
        "    # wiki_wiki = wikipediaapi.Wikipedia(\n",
        "    #     user_agent='FilmBot (ed.izaguirre@pm.me)',\n",
        "    #     language='en',\n",
        "    #     extract_format=wikipediaapi.ExtractFormat.WIKI\n",
        "    # )\n",
        "\n",
        "    # p_wiki = wiki_wiki.page(title)\n",
        "\n",
        "    # if p_wiki.exists():\n",
        "    #     # If wiki exists, append text\n",
        "    #     wiki_summary = p_wiki.text\n",
        "    # else:\n",
        "    #     # Otherwise, append a blank string\n",
        "    #     wiki_summary = \"\"\n",
        "\n",
        "    result = [title, runtime, language, overview,\n",
        "              release_year, genre_str, keyword_str,\n",
        "              actor_str, director_str, stream_str,\n",
        "              buy_str, rent_str, prod_str]\n",
        "\n",
        "    # write data\n",
        "    csvwriter.writerow(result)\n",
        "    csvFile.close()\n",
        "\n",
        "\n",
        "def is_english(s):\n",
        "    try:\n",
        "        s.encode(encoding='utf-8').decode('ascii')\n",
        "    except UnicodeDecodeError:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n"
      ],
      "metadata": {
        "id": "vbT55xMYWaVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **pull_data.ipynb**"
      ],
      "metadata": {
        "id": "OhAY34ZYmf_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtenção de todos os IDs de filmes"
      ],
      "metadata": {
        "id": "ETeiyfZ7oLop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No artigo, o autor pega o top 100 filmes de cada ano entre 1920 e 2023. Porém, observamos uma certa lentidão no download de informações da API do TMDB e para fins práticos, reduzimos o range de anos para 2014-2024."
      ],
      "metadata": {
        "id": "RP4FxxrH8dRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "years = [2014, 2024]\n",
        "\n",
        "YEARS = range(years[0], years[-1]+1)\n",
        "CSV_HEADER = ['Title', 'Runtime (minutes)', 'Language', 'Overview',\n",
        "              'Release Year', 'Genre', 'Keywords',\n",
        "              'Actors', 'Directors', 'Stream', 'Buy', 'Rent',\n",
        "              'Production Companies']"
      ],
      "metadata": {
        "id": "HprJGUTwXOM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Escrita dos IDs em arquivos CSV"
      ],
      "metadata": {
        "id": "fzVsco3IoWvO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui são chamadas as funções do arquivo utils.py"
      ],
      "metadata": {
        "id": "7Fgpa4o78b2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for year in YEARS:\n",
        "    # Grab list of ids for all films made in {YEAR}\n",
        "    movie_list = list(set(get_id_list(TMBD_API_KEY, year)))\n",
        "\n",
        "    FILE_PATH = './data/'\n",
        "    FILE_NAME = f'{FILE_PATH}{year}_movie_collection_data.csv'\n",
        "\n",
        "    if not os.path.exists(FILE_PATH):\n",
        "      os.makedirs(FILE_PATH)\n",
        "\n",
        "    # Creating file\n",
        "    with open(FILE_NAME, 'w') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(CSV_HEADER)\n",
        "\n",
        "    # Iterate through list of ids to get data\n",
        "    for id in movie_list:\n",
        "        data_dict = get_data(TMBD_API_KEY, id)\n",
        "        write_file(FILE_NAME, data_dict)"
      ],
      "metadata": {
        "id": "aaZJGiZQYA_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **rag_self_query.ipynb**"
      ],
      "metadata": {
        "id": "2Gt6aigQm3Qw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalação do LangChain"
      ],
      "metadata": {
        "id": "03lYOqNvokDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community langchain_openai langchain_pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG-2y2uTbK3e",
        "outputId": "2d858a44-41e6-40c8-a91e-467b948c5926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain_pinecone\n",
            "  Downloading langchain_pinecone-0.1.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain<0.3.0,>=0.2.15 (from langchain_community)\n",
            "  Downloading langchain-0.2.15-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core==0.2.36 (from langchain_community)\n",
            "  Downloading langchain_core-0.2.36-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n",
            "  Downloading langsmith-0.1.106-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.2.3)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core==0.2.36->langchain_community)\n",
            "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core==0.2.36->langchain_community) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core==0.2.36->langchain_community) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core==0.2.36->langchain_community) (4.10.0)\n",
            "Collecting openai<2.0.0,>=1.40.0 (from langchain_openai)\n",
            "  Downloading openai-1.42.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting pinecone-client<6.0.0,>=5.0.0 (from langchain_pinecone)\n",
            "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.15->langchain_community)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.0->langchain_community)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.9.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.9.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain_openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.2)\n",
            "Collecting typing-extensions>=4.7 (from langchain-core==0.2.36->langchain_community)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (2024.2.2)\n",
            "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone)\n",
            "  Downloading pinecone_plugin_inference-1.0.3-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (2.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.6)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.2.36->langchain_community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core==0.2.36->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core==0.2.36->langchain_community) (2.20.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Downloading langchain_community-0.2.14-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.36-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.1.23-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_pinecone-0.1.3-py3-none-any.whl (10 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain-0.2.15-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.106-py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.42.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-1.0.3-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.6/117.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Installing collected packages: typing-extensions, pinecone-plugin-interface, marshmallow, jsonpatch, jiter, httpcore, typing-inspect, tiktoken, pinecone-plugin-inference, httpx, pinecone-client, dataclasses-json, openai, langsmith, langchain-core, langchain-text-splitters, langchain_pinecone, langchain_openai, langchain, langchain_community\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.10.0\n",
            "    Uninstalling typing_extensions-4.10.0:\n",
            "      Successfully uninstalled typing_extensions-4.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 15.0.2 which is incompatible.\n",
            "tensorflow 2.17.0 requires flatbuffers>=24.3.25, but you have flatbuffers 24.3.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 jsonpatch-1.33 langchain-0.2.15 langchain-core-0.2.36 langchain-text-splitters-0.2.2 langchain_community-0.2.14 langchain_openai-0.1.23 langchain_pinecone-0.1.3 langsmith-0.1.106 marshmallow-3.22.0 openai-1.42.0 pinecone-client-5.0.1 pinecone-plugin-inference-1.0.3 pinecone-plugin-interface-0.0.7 tiktoken-0.7.0 typing-extensions-4.12.2 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports do LangChain"
      ],
      "metadata": {
        "id": "y_SBco8oo2zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pinecone\n",
        "from pinecone import Pinecone, PodSpec\n",
        "\n",
        "# Langchain\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.chains.query_constructor.base import (\n",
        "    StructuredQueryOutputParser,\n",
        "    get_query_constructor_prompt,\n",
        "    AttributeInfo\n",
        ")\n",
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain.retrievers.self_query.pinecone import PineconeTranslator\n",
        "from langchain_openai import (\n",
        "    ChatOpenAI,\n",
        "    OpenAIEmbeddings\n",
        ")\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain.indexes import SQLRecordManager, index\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# General\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "id": "Cvyyi4OXZLmj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ce73c92-db38-485b-9753-8179e4673513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversão de CSVs para Documentos"
      ],
      "metadata": {
        "id": "BQz1l-bQpEr7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O autor explica que fazer \"chunking\" geralmente é um processo importante em sistemas RAG, mas nesse caso cada documento será apenas 1 linha de cada arquivo CSV, tornando esse processo desnecessário."
      ],
      "metadata": {
        "id": "NME0wVb2-bFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O *DirectoryLoader* do LangChain carrega os arquivos CSV em documentos, e é necessário definir o que será o conteúdo principal (*page_content*) e o que será metadado (*metadata*). O *page_content* será usado na busca por similaridade, enquanto os metadados serão usados para filtragem antes da busca. Neste projeto, os atributos *overview* e *keywords* foram definidos como *page_content*, enquanto os demais atributos ficaram como metadados."
      ],
      "metadata": {
        "id": "Q102UD6o-15x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading in data from all csv files\n",
        "loader = DirectoryLoader(\n",
        "    path=\"./data\",\n",
        "    glob=\"*.csv\",\n",
        "    loader_cls=CSVLoader,\n",
        "    show_progress=True)\n",
        "\n",
        "docs = loader.load()\n",
        "\n",
        "metadata_field_info = [\n",
        "    AttributeInfo(\n",
        "        name=\"Title\", description=\"The title of the movie\", type=\"string\"),\n",
        "    AttributeInfo(name=\"Runtime (minutes)\",\n",
        "                  description=\"The runtime of the movie in minutes\", type=\"integer\"),\n",
        "    AttributeInfo(name=\"Language\",\n",
        "                  description=\"The language of the movie\", type=\"string\"),\n",
        "    AttributeInfo(name=\"Release Year\",\n",
        "                  description=\"The release year of the movie as an integer\", type=\"integer\"),\n",
        "    AttributeInfo(name=\"Genre\", description=\"The genre of the movie\",\n",
        "                  type=\"string or list[string]\"),\n",
        "    AttributeInfo(name=\"Actors\", description=\"The actors in the movie\",\n",
        "                  type=\"string or list[string]\"),\n",
        "    AttributeInfo(name=\"Directors\", description=\"The directors of the movie\",\n",
        "                  type=\"string or list[string]\"),\n",
        "    AttributeInfo(name=\"Stream\", description=\"The streaming platforms for the movie\",\n",
        "                  type=\"string or list[string]\"),\n",
        "    AttributeInfo(name=\"Buy\", description=\"The platforms where the movie can be bought\",\n",
        "                  type=\"string or list[string]\"),\n",
        "    AttributeInfo(name=\"Rent\", description=\"The platforms where the movie can be rented\",\n",
        "                  type=\"string or list[string]\"),\n",
        "    AttributeInfo(name=\"Production Companies\",\n",
        "                  description=\"The production companies of the movie\", type=\"string or list[string]\"),\n",
        "]\n",
        "\n",
        "def convert_to_list(doc, field):\n",
        "    if field in doc.metadata and doc.metadata[field] is not None:\n",
        "        doc.metadata[field] = [item.strip()\n",
        "                               for item in doc.metadata[field].split(',')]\n",
        "\n",
        "def convert_to_int(doc, field):\n",
        "    if field in doc.metadata and doc.metadata[field] is not None:\n",
        "        doc.metadata[field] = int(\n",
        "            doc.metadata[field])\n",
        "\n",
        "fields_to_convert_list = ['Genre', 'Actors', 'Directors',\n",
        "                          'Production Companies', 'Stream', 'Buy', 'Rent']\n",
        "fields_to_convert_int = ['Runtime (minutes)', 'Release Year']\n",
        "\n",
        "# Set 'overview' and 'keywords' as 'page_content' and other fields as 'metadata'\n",
        "for doc in docs:\n",
        "    # Parse the page_content string into a dictionary\n",
        "    page_content_dict = {}\n",
        "\n",
        "    for line in doc.page_content.split(\"\\n\"):\n",
        "        if \": \" in line:\n",
        "            key, value = line.split(\": \", 1)\n",
        "            page_content_dict[key] = value\n",
        "\n",
        "\n",
        "    doc.page_content = 'Overview: ' + page_content_dict.get(\n",
        "        'Overview') + '. Keywords: ' + page_content_dict.get('Keywords')\n",
        "    doc.metadata = {field.name: page_content_dict.get(\n",
        "        field.name) for field in metadata_field_info}\n",
        "\n",
        "    # Convert fields from string to list of strings\n",
        "    for field in fields_to_convert_list:\n",
        "        convert_to_list(doc, field)\n",
        "\n",
        "    # Convert fields from string to integers\n",
        "    for field in fields_to_convert_int:\n",
        "        convert_to_int(doc, field)"
      ],
      "metadata": {
        "id": "sgVK247wZVSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6295eae-7bf2-4dd6-9ada-8a411793c95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 272.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[5])"
      ],
      "metadata": {
        "id": "U7LBqXxRZWis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cd029fc-4c32-4232-ac46-73b8bfe1dff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Overview: Kubo mesmerizes the people in his village with his magical gift for spinning wild tales with origami. When he accidentally summons an evil spirit seeking vengeance, Kubo is forced to go on a quest to solve the mystery of his fallen samurai father and his mystical weaponry, as well as discover his own magical powers.. Keywords: japan, samurai, magic, forgiveness, stop motion, storytelling, origami, feudal japan, mother son relationship' metadata={'Title': 'Kubo and the Two Strings', 'Runtime (minutes)': 102, 'Language': 'English', 'Release Year': 2016, 'Genre': ['Animation', 'Adventure', 'Family'], 'Actors': ['Brenda Vaccaro', 'Charlize Theron', 'Cary-Hiroyuki Tagawa', 'Art Parkinson', 'Meyrick Murphy'], 'Directors': ['Travis Knight'], 'Stream': [''], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'Spectrum On Demand'], 'Production Companies': ['Laika']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criação do Index no Pinecone e upload de Documentos"
      ],
      "metadata": {
        "id": "t5lpcVV9pLKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Pinecone permite o armazenamento dos documentos na nuvem."
      ],
      "metadata": {
        "id": "c_5Jqa9eAjkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty index\n",
        "pc = Pinecone(api_key=PINECONE_KEY)\n",
        "\n",
        "# Uncomment if index is not created already\n",
        "# pc.create_index(\n",
        "#     name=PINECONE_INDEX_NAME,\n",
        "#     dimension=1536,\n",
        "#     metric=\"cosine\",\n",
        "#     spec=PodSpec(\n",
        "#         environment=\"gcp-starter\"\n",
        "#     )\n",
        "# )\n",
        "\n",
        "# Target index and check status\n",
        "pc_index = pc.Index(PINECONE_INDEX_NAME)\n",
        "print(pc_index.describe_index_stats())\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002', openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "vectorstore = PineconeVectorStore(\n",
        "    pc_index, embeddings\n",
        ")\n",
        "\n",
        "# Create record manager\n",
        "namespace = f\"pinecone/{PINECONE_INDEX_NAME}\"\n",
        "record_manager = SQLRecordManager(\n",
        "    namespace, db_url=\"sqlite:///record_manager_cache.sql\"\n",
        ")\n",
        "\n",
        "record_manager.create_schema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlWh3Lo5esXT",
        "outputId": "4fa25223-53d8-4eb4-f45a-5cb575f6c813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dimension': 1536,\n",
            " 'index_fullness': 0.0,\n",
            " 'namespaces': {'': {'vector_count': 4540}},\n",
            " 'total_vector_count': 4540}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função index faz o upload dos documentos"
      ],
      "metadata": {
        "id": "Rzu5ztQnCThK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _clear():\n",
        "    \"\"\"\n",
        "    Hacky helper method to clear content.\n",
        "    \"\"\"\n",
        "    index([], record_manager, vectorstore,\n",
        "          cleanup=\"full\", source_id_key=\"Title\")\n",
        "\n",
        "# Uncomment this line if you want to clear the Pinecone vectorstore\n",
        "_clear()\n",
        "\n",
        "# Upload documents to pinecome\n",
        "index(docs, record_manager, vectorstore, cleanup=\"full\", source_id_key=\"Title\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1KG6ZQMglm1",
        "outputId": "c1eb8ac4-4d27-444f-89e1-a19b07ba71e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_added': 1099, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criação de Self-Querying Retriever"
      ],
      "metadata": {
        "id": "yuL2NzxPpauR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este é o processo anterior à busca por similaridade. Aqui  os filmes são filtrados com dados mais \"objetivos\", como ano de lançamento.\n",
        "\n",
        "São definidios comparadores, exemplos de queries e filtros correspondentes (essa técnica é conhecida como few-shot learning)."
      ],
      "metadata": {
        "id": "hEV2o1RsDrW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_content_description = \"Brief overview of a movie, along with keywords\"\n",
        "\n",
        "# Define allowed comparators list\n",
        "allowed_comparators = [\n",
        "    \"$eq\",  # Equal to (number, string, boolean)\n",
        "    \"$ne\",  # Not equal to (number, string, boolean)\n",
        "    \"$gt\",  # Greater than (number)\n",
        "    \"$gte\",  # Greater than or equal to (number)\n",
        "    \"$lt\",  # Less than (number)\n",
        "    \"$lte\",  # Less than or equal to (number)\n",
        "    \"$in\",  # In array (string or number)\n",
        "    \"$nin\",  # Not in array (string or number)\n",
        "]\n",
        "\n",
        "examples = [\n",
        "    (\n",
        "        \"I'm looking for a sci-fi comedy released after 2021.\",\n",
        "        {\n",
        "            \"query\": \"sci-fi comedy\",\n",
        "            \"filter\": \"and(eq('Genre', 'Science'), eq('Genre', 'Comedy'), gt('Release Year', 2021))\",\n",
        "        },\n",
        "    ),\n",
        "    (\n",
        "        \"Show me critically acclaimed dramas without Tom Hanks.\",\n",
        "        {\n",
        "            \"query\": \"critically acclaimed drama\",\n",
        "            \"filter\": \"and(eq('Genre', 'Drama'), nin('Actors', ['Tom Hanks']))\",\n",
        "        },\n",
        "    ),\n",
        "    (\n",
        "        \"Recommend some films by Yorgos Lanthimos.\",\n",
        "        {\n",
        "            \"query\": \"Yorgos Lanthimos\",\n",
        "            \"filter\": 'in(\"Directors\", [\"Yorgos Lanthimos]\")',\n",
        "        },\n",
        "    ),\n",
        "    (\n",
        "        \"Films similar to Yorgos Lanthmios movies.\",\n",
        "        {\n",
        "            \"query\": \"Dark comedy, absurd, Greek Weird Wave\",\n",
        "            \"filter\": 'NO_FILTER',\n",
        "        },\n",
        "    ),\n",
        "    (\n",
        "        \"Find me thrillers with a strong female lead released between 2015 and 2020.\",\n",
        "        {\n",
        "            \"query\": \"thriller strong female lead\",\n",
        "            \"filter\": \"and(eq('Genre', 'Thriller'), gt('Release Year', 2015), lt('Release Year', 2021))\",\n",
        "        },\n",
        "    ),\n",
        "    (\n",
        "        \"Find me highly rated drama movies in English that are less than 2 hours long\",\n",
        "        {\n",
        "            \"query\": \"Highly rated drama English under 2 hours\",\n",
        "            \"filter\": 'and(eq(\"Genre\", \"Drama\"), eq(\"Language\", \"English\"), lt(\"Runtime (minutes)\", 120))',\n",
        "        },\n",
        "    ),\n",
        "]\n",
        "\n",
        "constructor_prompt = get_query_constructor_prompt(\n",
        "    document_content_description,\n",
        "    metadata_field_info,\n",
        "    allowed_comparators=allowed_comparators,\n",
        "    examples=examples,\n",
        ")\n",
        "\n",
        "query_model = ChatOpenAI(\n",
        "    # model='gpt-3.5-turbo-0125',\n",
        "    model='gpt-4o',\n",
        "    temperature=0,\n",
        "    streaming=True,\n",
        "    openai_api_key=OPENAI_API_KEY\n",
        ")\n",
        "\n",
        "output_parser = StructuredQueryOutputParser.from_components()\n",
        "query_constructor = constructor_prompt | query_model | output_parser"
      ],
      "metadata": {
        "id": "y-50WU6mh-4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Comedy films\"\n",
        "# question = \"Find me thrillers with a strong female lead released between 2015 and 2020.\"\n",
        "# print(constructor_prompt.format(query=question))\n",
        "# print(type(constructor_prompt))"
      ],
      "metadata": {
        "id": "8Nr3E7I2iOew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_constructor.invoke(\n",
        "    {\n",
        "        \"query\": question\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9iozxfPiUg1",
        "outputId": "e58e3bc7-bb84-4195-d84f-67a3305d8df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructuredQuery(query='comedy', filter=None, limit=None)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = SelfQueryRetriever(\n",
        "    query_constructor=query_constructor,\n",
        "    vectorstore=vectorstore,\n",
        "    structured_query_translator=PineconeTranslator(),\n",
        "    search_kwargs={'k': 10}\n",
        ")\n",
        "\n",
        "retriever.invoke(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Di3yAEIiWF2",
        "outputId": "361c50a0-4263-48cc-9dac-c2afcfb91b4c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'Actors': ['Kevin Hart', 'Ed Helms', 'Thomas Middleditch', 'Nick Kroll', 'Jordan Peele'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['David Soren'], 'Genre': ['Action', 'Animation', 'Comedy', 'Family'], 'Language': 'English', 'Production Companies': ['DreamWorks Animation', 'Scholastic Entertainment'], 'Release Year': 2017.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 89.0, 'Stream': ['Netflix', 'Netflix basic with Ads'], 'Title': 'Captain Underpants: The First Epic Movie'}, page_content=\"Overview: Based on the bestselling book series, this outrageous comedy tells the story of George and Harold,  two overly imaginative pranksters who hypnotize their principal into thinking he’s an enthusiastic, yet dimwitted, superhero named Captain Underpants.. Keywords: friendship, based on novel or book, superhero, underwear, villain, comic book, school, principal, based on children's book, grade school, sock puppet, excited, vibrant\"),\n",
              " Document(metadata={'Actors': ['Kevin Hart', 'Jordan Peele', 'Nick Kroll', 'Thomas Middleditch', 'Ed Helms'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['David Soren'], 'Genre': ['Action', 'Animation', 'Comedy', 'Family'], 'Language': 'English', 'Production Companies': ['DreamWorks Animation', 'Scholastic Entertainment'], 'Release Year': 2017.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 89.0, 'Stream': ['Netflix', 'Netflix basic with Ads'], 'Title': 'Captain Underpants: The First Epic Movie'}, page_content=\"Overview: Based on the bestselling book series, this outrageous comedy tells the story of George and Harold,  two overly imaginative pranksters who hypnotize their principal into thinking he’s an enthusiastic, yet dimwitted, superhero named Captain Underpants.. Keywords: friendship, based on novel or book, superhero, underwear, villain, comic book, school, principal, based on children's book, grade school, sock puppet, excited, vibrant\"),\n",
              " Document(metadata={'Actors': ['David Duchovny', 'Ted Levine', 'Orlando Jones', 'Julianne Moore', 'Seann William Scott'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['Ivan Reitman'], 'Genre': ['Comedy', 'Science Fiction', 'Action'], 'Language': 'English', 'Production Companies': ['DreamWorks Pictures', 'Columbia Pictures', 'The Montecito Picture Company'], 'Release Year': 2001.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 101.0, 'Stream': ['fuboTV', 'Starz Apple TV Channel'], 'Title': 'Evolution'}, page_content='Overview: A comedy that follows the chaos that ensues when a meteor hits the Earth carrying alien life forms that give new meaning to the term \"survival of the fittest.\" David Duchovny, Orlando Jones, Seann William Scott, and Julianne Moore are the only people standing between the aliens and world domination... which could be bad news for the Earth.. Keywords: governor, fire engine, giant monster, grand canyon, alien life-form, shampoo, evolution, high school teacher, government scientist, napalm, primate, advertisement'),\n",
              " Document(metadata={'Actors': ['Jordan Peele', 'Thomas Middleditch', 'Ed Helms', 'Kevin Hart', 'Nick Kroll'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['David Soren'], 'Genre': ['Action', 'Animation', 'Comedy', 'Family'], 'Language': 'English', 'Production Companies': ['DreamWorks Animation', 'Scholastic Entertainment'], 'Release Year': 2017.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 89.0, 'Stream': ['Netflix', 'Netflix basic with Ads'], 'Title': 'Captain Underpants: The First Epic Movie'}, page_content=\"Overview: Based on the bestselling book series, this outrageous comedy tells the story of George and Harold,  two overly imaginative pranksters who hypnotize their principal into thinking he’s an enthusiastic, yet dimwitted, superhero named Captain Underpants.. Keywords: friendship, based on novel or book, superhero, underwear, villain, comic book, school, principal, based on children's book, grade school, sock puppet, excited, vibrant\"),\n",
              " Document(metadata={'Actors': ['Jeff Anderson', 'Kevin Smith', 'Ben Affleck', \"Brian O'Halloran\", 'Jason Mewes'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['Kevin Smith'], 'Genre': ['Comedy'], 'Language': 'English', 'Production Companies': ['Dimension Films', 'View Askew Productions'], 'Release Year': 2001.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 104.0, 'Stream': ['Amazon Prime Video', 'fuboTV', 'Epix Amazon Channel', 'Paramount Plus', 'Paramount Plus Apple TV Channel', 'Paramount+ Amazon Channel', 'MGM Plus Roku Premium Channel', 'MGM Plus', 'Showtime Apple TV Channel', 'Amazon Prime Video with Ads'], 'Title': 'Jay and Silent Bob Strike Back'}, page_content='Overview: When Jay and Silent Bob learn that their comic-book alter egos, Bluntman and Chronic, have been sold to Hollywood as part of a big-screen movie that leaves them out of any royalties, the pair travels to Tinseltown to sabotage the production.. Keywords: experiment, movie business, comic book, breaking the fourth wall, self mocking, monkey actor, gigantic hand'),\n",
              " Document(metadata={'Actors': ['Anna Faris', 'Shawn Wayans', 'Regina Hall', 'Jon Abrahams', 'Marlon Wayans'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['Keenen Ivory Wayans'], 'Genre': ['Comedy'], 'Language': 'English', 'Production Companies': ['Brad Grey Pictures', 'Gold/Miller Productions', 'Wayans Bros. Entertainment', 'Dimension Films'], 'Release Year': 2000.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 88.0, 'Stream': [''], 'Title': 'Scary Movie'}, page_content='Overview: A familiar-looking group of teenagers find themselves being stalked by a more-than-vaguely recognizable masked killer! As the victims begin to pile up and the laughs pile on, none of your favorite scary movies escape the razor-sharp satire of this outrageously funny parody!. Keywords: high school, psychopath, garage, satire, parody, crude humor, spoof, horror spoof, drugs, aftercreditsstinger, horror parody'),\n",
              " Document(metadata={'Actors': ['Kelsey Grammer', 'Sarah Jessica Parker', 'Christina Hendricks', 'Pierce Brosnan', 'Greg Kinnear'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home'], 'Directors': ['Douglas McGrath'], 'Genre': ['Romance', 'Comedy'], 'Language': 'English', 'Production Companies': ['The Weinstein Company'], 'Release Year': 2011.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home'], 'Runtime (minutes)': 89.0, 'Stream': ['Max', 'Max Amazon Channel', 'Starz Apple TV Channel'], 'Title': \"I Don't Know How She Does It\"}, page_content='Overview: A comedy centered on the life of Kate Reddy, a finance executive who is the breadwinner for her husband and two kids.. Keywords: pregnancy, family vacation, widower, working mum, in-laws'),\n",
              " Document(metadata={'Actors': ['Kerry Condon', 'Gary Lydon', 'Barry Keoghan', 'Brendan Gleeson', 'Colin Farrell'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['Martin McDonagh'], 'Genre': ['Drama', 'Comedy'], 'Language': 'English', 'Production Companies': ['Searchlight Pictures', 'Blueprint Pictures', 'Film4 Productions', 'TSG Entertainment'], 'Release Year': 2022.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'Spectrum On Demand'], 'Runtime (minutes)': 114.0, 'Stream': [''], 'Title': 'The Banshees of Inisherin'}, page_content='Overview: Two lifelong friends find themselves at an impasse when one abruptly ends their relationship, with alarming consequences for both of them.. Keywords: friendship, island, donkey, dark comedy, irish civil war (1922-23), church, ireland, drinking, former best friend, self mutilation, fiddle, 1920s, brother sister relationship, pub'),\n",
              " Document(metadata={'Actors': ['Colin Farrell', 'Barry Keoghan', 'Brendan Gleeson', 'Kerry Condon', 'Gary Lydon'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['Martin McDonagh'], 'Genre': ['Drama', 'Comedy'], 'Language': 'English', 'Production Companies': ['Searchlight Pictures', 'Blueprint Pictures', 'Film4 Productions', 'TSG Entertainment'], 'Release Year': 2022.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'Spectrum On Demand'], 'Runtime (minutes)': 114.0, 'Stream': [''], 'Title': 'The Banshees of Inisherin'}, page_content='Overview: Two lifelong friends find themselves at an impasse when one abruptly ends their relationship, with alarming consequences for both of them.. Keywords: friendship, island, donkey, dark comedy, irish civil war (1922-23), church, ireland, drinking, former best friend, self mutilation, fiddle, 1920s, brother sister relationship, pub'),\n",
              " Document(metadata={'Actors': ['Jason Mantzoukas', 'Sayed Badreya', 'Anna Faris', 'Ben Kingsley', 'Sacha Baron Cohen'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['Larry Charles'], 'Genre': ['Comedy'], 'Language': 'English', 'Production Companies': ['Paramount Pictures', 'Four by Two', 'Berg Mandel Schaffer Productions', 'Scott Rudin Productions'], 'Release Year': 2012.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 83.0, 'Stream': [''], 'Title': 'The Dictator'}, page_content=\"Overview: The heroic story of a dictator who risks his life to ensure that democracy would never come to the country he so lovingly oppressed.. Keywords: petrol, culture clash, dictator, coup d'etat, satire, parody, uncle, conspiracy, female soldier, united nations, weapon of mass destruction, dissident, grocery store, identity swap, ironic, hilarious\")]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criação de RAG Chain"
      ],
      "metadata": {
        "id": "D2lN1YWPpjJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depois de construir o *self-querying retriever*, o próximo passo é desenvolver o modelo RAG padrão. O processo começa definindo um modelo de chat, que recebe um contexto (filmes recuperados + mensagem do sistema) e responde com um resumo de cada recomendação. Uma parte essencial dessa configuração é a mensagem do sistema, que define o objetivo do bot e impõe regras, como a restrição de não recomendar filmes que não estejam no contexto fornecido pelo *self-querying retriever*. Essa abordagem evita que o modelo recomende filmes inexistentes ou fora do escopo da busca, garantindo respostas precisas e confiáveis.\n",
        "\n",
        "A mensagem do sistema é detalhada através de um template de prompt, instruindo o modelo a recomendar de três a cinco filmes com base no contexto, sem exceder esse limite e sem sugerir filmes não encontrados pelo retriever. A função `format_docs` é usada para organizar e apresentar as informações dos filmes ao modelo, combinando o *page_content* e os metadados. O *rag_chain_from_docs* é uma cadeia que formata os documentos recuperados e os passa ao modelo para gerar respostas. Em seguida, `rag_chain_with_source` é criado como um *RunnableParallel*, que simultaneamente recupera documentos relevantes e passa a consulta ao modelo, combinando os resultados para gerar a resposta final. O trecho final do código garante que a resposta seja transmitida ao usuário em tempo real, simulando a experiência de interação contínua, como a que vemos no ChatGPT."
      ],
      "metadata": {
        "id": "koNqPuArFyVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(f\"{doc.page_content}\\n\\nMetadata: {doc.metadata}\" for doc in docs)\n",
        "\n",
        "chat_model = ChatOpenAI(\n",
        "    model='gpt-4o-mini',\n",
        "    # model='gpt-4-0125-preview',\n",
        "    temperature=0,\n",
        "    streaming=True,\n",
        "    openai_api_key=OPENAI_API_KEY\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            'system',\n",
        "            \"\"\"\n",
        "            Your goal is to recommend films to users based on their\n",
        "            query and the retrieved context. If a retrieved film doesn't seem\n",
        "            relevant, omit it from your response. Never refer to films that\n",
        "            are not in your context. If you cannot recommend any\n",
        "            films, suggest better queries to the user. You cannot\n",
        "            recommend more than five films. Your recommendation should\n",
        "            be relevant, original, and at least two to three sentences\n",
        "            long.\n",
        "\n",
        "            YOU CANNOT RECOMMEND A FILM IF IT DOES NOT APPEAR IN YOUR\n",
        "            CONTEXT.\n",
        "\n",
        "            # TEMPLATE FOR OUTPUT\n",
        "            - [Title of Film](source link):\n",
        "                - Runtime:\n",
        "                - Release Year:\n",
        "                - (Your reasoning for recommending this film)\n",
        "\n",
        "            Question: {question}\n",
        "            Context: {context}\n",
        "            \"\"\"\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create a chatbot Question & Answer chain from the retriever\n",
        "rag_chain_from_docs = (\n",
        "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
        "    | prompt\n",
        "    | chat_model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "rag_chain_with_source = RunnableParallel(\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        ").assign(answer=rag_chain_from_docs)\n",
        "\n",
        "\n",
        "query_constructor.invoke(\n",
        "    {\n",
        "        \"query\": question\n",
        "    }\n",
        ")\n",
        "# Only prints final answer\n",
        "# for chunk in rag_chain_with_source.stream(question):\n",
        "#     for key in chunk:\n",
        "#         if key == 'answer':\n",
        "#             print(chunk[key], end=\"\", flush=True)\n",
        "\n",
        "# Prints everything\n",
        "output = {}\n",
        "curr_key = None\n",
        "for chunk in rag_chain_with_source.stream(question):\n",
        "    for key in chunk:\n",
        "        if key not in output:\n",
        "            output[key] = chunk[key]\n",
        "        else:\n",
        "            output[key] += chunk[key]\n",
        "        if key != curr_key:\n",
        "            print(f\"\\n\\n{key}: {chunk[key]}\", end=\"\", flush=True)\n",
        "        else:\n",
        "            print(chunk[key], end=\"\", flush=True)\n",
        "        curr_key = key\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuyPUuUzifL9",
        "outputId": "1621d23c-1343-47f6-dd05-dc1846f846ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "question: Comedy films\n",
            "\n",
            "context: [Document(metadata={'Actors': ['Kevin Hart', 'Jordan Peele', 'Nick Kroll', 'Thomas Middleditch', 'Ed Helms'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['David Soren'], 'Genre': ['Action', 'Animation', 'Comedy', 'Family'], 'Language': 'English', 'Production Companies': ['DreamWorks Animation', 'Scholastic Entertainment'], 'Release Year': 2017.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 89.0, 'Stream': ['Netflix', 'Netflix basic with Ads'], 'Title': 'Captain Underpants: The First Epic Movie'}, page_content=\"Overview: Based on the bestselling book series, this outrageous comedy tells the story of George and Harold,  two overly imaginative pranksters who hypnotize their principal into thinking he’s an enthusiastic, yet dimwitted, superhero named Captain Underpants.. Keywords: friendship, based on novel or book, superhero, underwear, villain, comic book, school, principal, based on children's book, grade school, sock puppet, excited, vibrant\"), Document(metadata={'Actors': ['Kevin Hart', 'Ed Helms', 'Thomas Middleditch', 'Nick Kroll', 'Jordan Peele'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['David Soren'], 'Genre': ['Action', 'Animation', 'Comedy', 'Family'], 'Language': 'English', 'Production Companies': ['DreamWorks Animation', 'Scholastic Entertainment'], 'Release Year': 2017.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 89.0, 'Stream': ['Netflix', 'Netflix basic with Ads'], 'Title': 'Captain Underpants: The First Epic Movie'}, page_content=\"Overview: Based on the bestselling book series, this outrageous comedy tells the story of George and Harold,  two overly imaginative pranksters who hypnotize their principal into thinking he’s an enthusiastic, yet dimwitted, superhero named Captain Underpants.. Keywords: friendship, based on novel or book, superhero, underwear, villain, comic book, school, principal, based on children's book, grade school, sock puppet, excited, vibrant\"), Document(metadata={'Actors': ['David Duchovny', 'Ted Levine', 'Orlando Jones', 'Julianne Moore', 'Seann William Scott'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['Ivan Reitman'], 'Genre': ['Comedy', 'Science Fiction', 'Action'], 'Language': 'English', 'Production Companies': ['DreamWorks Pictures', 'Columbia Pictures', 'The Montecito Picture Company'], 'Release Year': 2001.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 101.0, 'Stream': ['fuboTV', 'Starz Apple TV Channel'], 'Title': 'Evolution'}, page_content='Overview: A comedy that follows the chaos that ensues when a meteor hits the Earth carrying alien life forms that give new meaning to the term \"survival of the fittest.\" David Duchovny, Orlando Jones, Seann William Scott, and Julianne Moore are the only people standing between the aliens and world domination... which could be bad news for the Earth.. Keywords: governor, fire engine, giant monster, grand canyon, alien life-form, shampoo, evolution, high school teacher, government scientist, napalm, primate, advertisement'), Document(metadata={'Actors': ['Jordan Peele', 'Thomas Middleditch', 'Ed Helms', 'Kevin Hart', 'Nick Kroll'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['David Soren'], 'Genre': ['Action', 'Animation', 'Comedy', 'Family'], 'Language': 'English', 'Production Companies': ['DreamWorks Animation', 'Scholastic Entertainment'], 'Release Year': 2017.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 89.0, 'Stream': ['Netflix', 'Netflix basic with Ads'], 'Title': 'Captain Underpants: The First Epic Movie'}, page_content=\"Overview: Based on the bestselling book series, this outrageous comedy tells the story of George and Harold,  two overly imaginative pranksters who hypnotize their principal into thinking he’s an enthusiastic, yet dimwitted, superhero named Captain Underpants.. Keywords: friendship, based on novel or book, superhero, underwear, villain, comic book, school, principal, based on children's book, grade school, sock puppet, excited, vibrant\"), Document(metadata={'Actors': ['Jeff Anderson', 'Kevin Smith', 'Ben Affleck', \"Brian O'Halloran\", 'Jason Mewes'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['Kevin Smith'], 'Genre': ['Comedy'], 'Language': 'English', 'Production Companies': ['Dimension Films', 'View Askew Productions'], 'Release Year': 2001.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 104.0, 'Stream': ['Amazon Prime Video', 'fuboTV', 'Epix Amazon Channel', 'Paramount Plus', 'Paramount Plus Apple TV Channel', 'Paramount+ Amazon Channel', 'MGM Plus Roku Premium Channel', 'MGM Plus', 'Showtime Apple TV Channel', 'Amazon Prime Video with Ads'], 'Title': 'Jay and Silent Bob Strike Back'}, page_content='Overview: When Jay and Silent Bob learn that their comic-book alter egos, Bluntman and Chronic, have been sold to Hollywood as part of a big-screen movie that leaves them out of any royalties, the pair travels to Tinseltown to sabotage the production.. Keywords: experiment, movie business, comic book, breaking the fourth wall, self mocking, monkey actor, gigantic hand'), Document(metadata={'Actors': ['Anna Faris', 'Shawn Wayans', 'Regina Hall', 'Jon Abrahams', 'Marlon Wayans'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['Keenen Ivory Wayans'], 'Genre': ['Comedy'], 'Language': 'English', 'Production Companies': ['Brad Grey Pictures', 'Gold/Miller Productions', 'Wayans Bros. Entertainment', 'Dimension Films'], 'Release Year': 2000.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 88.0, 'Stream': [''], 'Title': 'Scary Movie'}, page_content='Overview: A familiar-looking group of teenagers find themselves being stalked by a more-than-vaguely recognizable masked killer! As the victims begin to pile up and the laughs pile on, none of your favorite scary movies escape the razor-sharp satire of this outrageously funny parody!. Keywords: high school, psychopath, garage, satire, parody, crude humor, spoof, horror spoof, drugs, aftercreditsstinger, horror parody'), Document(metadata={'Actors': ['Kelsey Grammer', 'Sarah Jessica Parker', 'Christina Hendricks', 'Pierce Brosnan', 'Greg Kinnear'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home'], 'Directors': ['Douglas McGrath'], 'Genre': ['Romance', 'Comedy'], 'Language': 'English', 'Production Companies': ['The Weinstein Company'], 'Release Year': 2011.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home'], 'Runtime (minutes)': 89.0, 'Stream': ['Max', 'Max Amazon Channel', 'Starz Apple TV Channel'], 'Title': \"I Don't Know How She Does It\"}, page_content='Overview: A comedy centered on the life of Kate Reddy, a finance executive who is the breadwinner for her husband and two kids.. Keywords: pregnancy, family vacation, widower, working mum, in-laws'), Document(metadata={'Actors': ['Kerry Condon', 'Gary Lydon', 'Barry Keoghan', 'Brendan Gleeson', 'Colin Farrell'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['Martin McDonagh'], 'Genre': ['Drama', 'Comedy'], 'Language': 'English', 'Production Companies': ['Searchlight Pictures', 'Blueprint Pictures', 'Film4 Productions', 'TSG Entertainment'], 'Release Year': 2022.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'Spectrum On Demand'], 'Runtime (minutes)': 114.0, 'Stream': [''], 'Title': 'The Banshees of Inisherin'}, page_content='Overview: Two lifelong friends find themselves at an impasse when one abruptly ends their relationship, with alarming consequences for both of them.. Keywords: friendship, island, donkey, dark comedy, irish civil war (1922-23), church, ireland, drinking, former best friend, self mutilation, fiddle, 1920s, brother sister relationship, pub'), Document(metadata={'Actors': ['Colin Farrell', 'Barry Keoghan', 'Brendan Gleeson', 'Kerry Condon', 'Gary Lydon'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['Martin McDonagh'], 'Genre': ['Drama', 'Comedy'], 'Language': 'English', 'Production Companies': ['Searchlight Pictures', 'Blueprint Pictures', 'Film4 Productions', 'TSG Entertainment'], 'Release Year': 2022.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'Spectrum On Demand'], 'Runtime (minutes)': 114.0, 'Stream': [''], 'Title': 'The Banshees of Inisherin'}, page_content='Overview: Two lifelong friends find themselves at an impasse when one abruptly ends their relationship, with alarming consequences for both of them.. Keywords: friendship, island, donkey, dark comedy, irish civil war (1922-23), church, ireland, drinking, former best friend, self mutilation, fiddle, 1920s, brother sister relationship, pub'), Document(metadata={'Actors': ['Jason Mantzoukas', 'Sayed Badreya', 'Anna Faris', 'Ben Kingsley', 'Sacha Baron Cohen'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['Larry Charles'], 'Genre': ['Comedy'], 'Language': 'English', 'Production Companies': ['Paramount Pictures', 'Four by Two', 'Berg Mandel Schaffer Productions', 'Scott Rudin Productions'], 'Release Year': 2012.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 83.0, 'Stream': [''], 'Title': 'The Dictator'}, page_content=\"Overview: The heroic story of a dictator who risks his life to ensure that democracy would never come to the country he so lovingly oppressed.. Keywords: petrol, culture clash, dictator, coup d'etat, satire, parody, uncle, conspiracy, female soldier, united nations, weapon of mass destruction, dissident, grocery store, identity swap, ironic, hilarious\")]\n",
            "\n",
            "answer: - [Captain Underpants: The First Epic Movie](https://www.netflix.com/title/80100100):\n",
            "    - Runtime: 89 minutes\n",
            "    - Release Year: 2017\n",
            "    - This animated comedy is a delightful adaptation of the beloved children's book series. It follows the hilarious antics of two prankster friends who hypnotize their principal into becoming a superhero. The vibrant animation and playful humor make it a perfect choice for family viewing, ensuring laughs for both kids and adults alike.\n",
            "\n",
            "- [Evolution](https://www.amazon.com/Evolution-David-Duchovny/dp/B000I9F8D4):\n",
            "    - Runtime: 101 minutes\n",
            "    - Release Year: 2001\n",
            "    - This sci-fi comedy brings a unique twist to the genre, as it combines humor with an alien invasion plot. With a stellar cast including David Duchovny and Julianne Moore, the film delivers a mix of laughs and action as the characters navigate the chaos caused by extraterrestrial life forms. It's a fun ride that keeps you entertained from start to finish.\n",
            "\n",
            "- [Jay and Silent Bob Strike Back](https://www.amazon.com/Jay-Silent-Bob-Strike-Back/dp/B000I9F8D4):\n",
            "    - Runtime: 104 minutes\n",
            "    - Release Year: 2001\n",
            "    - This film is a must-watch for fans of Kevin Smith's unique brand of humor. Following the misadventures of Jay and Silent Bob as they attempt to sabotage a movie based on their comic book characters, it’s filled with self-referential jokes and a plethora of cameos. It's a hilarious take on the film industry that will resonate with anyone who appreciates a good comedy.\n",
            "\n",
            "- [Scary Movie](https://www.amazon.com/Scary-Movie-Anna-Faris/dp/B000I9F8D4):\n",
            "    - Runtime: 88 minutes\n",
            "    - Release Year: 2000\n",
            "    - As a parody of popular horror films, \"Scary Movie\" delivers a blend of crude humor and clever satire. It pokes fun at the clichés of the genre while providing plenty of laugh-out-loud moments. If you're in the mood for a comedy that doesn't take itself too seriously, this film is a perfect choice.\n",
            "\n",
            "- [The Dictator](https://www.amazon.com/Dictator-Sacha-Baron-Cohen/dp/B0078G8D8A):\n",
            "    - Runtime: 83 minutes\n",
            "    - Release Year: 2012\n",
            "    - This satirical comedy features Sacha Baron Cohen as a dictator who goes to great lengths to ensure his oppressive regime remains intact. The film is filled with outrageous humor and sharp social commentary, making it both entertaining and thought-provoking. If you're looking for a comedy that pushes boundaries, \"The Dictator\" is sure to deliver."
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Comedy films',\n",
              " 'context': [Document(metadata={'Actors': ['Kevin Hart', 'Jordan Peele', 'Nick Kroll', 'Thomas Middleditch', 'Ed Helms'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['David Soren'], 'Genre': ['Action', 'Animation', 'Comedy', 'Family'], 'Language': 'English', 'Production Companies': ['DreamWorks Animation', 'Scholastic Entertainment'], 'Release Year': 2017.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 89.0, 'Stream': ['Netflix', 'Netflix basic with Ads'], 'Title': 'Captain Underpants: The First Epic Movie'}, page_content=\"Overview: Based on the bestselling book series, this outrageous comedy tells the story of George and Harold,  two overly imaginative pranksters who hypnotize their principal into thinking he’s an enthusiastic, yet dimwitted, superhero named Captain Underpants.. Keywords: friendship, based on novel or book, superhero, underwear, villain, comic book, school, principal, based on children's book, grade school, sock puppet, excited, vibrant\"),\n",
              "  Document(metadata={'Actors': ['Kevin Hart', 'Ed Helms', 'Thomas Middleditch', 'Nick Kroll', 'Jordan Peele'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['David Soren'], 'Genre': ['Action', 'Animation', 'Comedy', 'Family'], 'Language': 'English', 'Production Companies': ['DreamWorks Animation', 'Scholastic Entertainment'], 'Release Year': 2017.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 89.0, 'Stream': ['Netflix', 'Netflix basic with Ads'], 'Title': 'Captain Underpants: The First Epic Movie'}, page_content=\"Overview: Based on the bestselling book series, this outrageous comedy tells the story of George and Harold,  two overly imaginative pranksters who hypnotize their principal into thinking he’s an enthusiastic, yet dimwitted, superhero named Captain Underpants.. Keywords: friendship, based on novel or book, superhero, underwear, villain, comic book, school, principal, based on children's book, grade school, sock puppet, excited, vibrant\"),\n",
              "  Document(metadata={'Actors': ['David Duchovny', 'Ted Levine', 'Orlando Jones', 'Julianne Moore', 'Seann William Scott'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['Ivan Reitman'], 'Genre': ['Comedy', 'Science Fiction', 'Action'], 'Language': 'English', 'Production Companies': ['DreamWorks Pictures', 'Columbia Pictures', 'The Montecito Picture Company'], 'Release Year': 2001.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 101.0, 'Stream': ['fuboTV', 'Starz Apple TV Channel'], 'Title': 'Evolution'}, page_content='Overview: A comedy that follows the chaos that ensues when a meteor hits the Earth carrying alien life forms that give new meaning to the term \"survival of the fittest.\" David Duchovny, Orlando Jones, Seann William Scott, and Julianne Moore are the only people standing between the aliens and world domination... which could be bad news for the Earth.. Keywords: governor, fire engine, giant monster, grand canyon, alien life-form, shampoo, evolution, high school teacher, government scientist, napalm, primate, advertisement'),\n",
              "  Document(metadata={'Actors': ['Jordan Peele', 'Thomas Middleditch', 'Ed Helms', 'Kevin Hart', 'Nick Kroll'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['David Soren'], 'Genre': ['Action', 'Animation', 'Comedy', 'Family'], 'Language': 'English', 'Production Companies': ['DreamWorks Animation', 'Scholastic Entertainment'], 'Release Year': 2017.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 89.0, 'Stream': ['Netflix', 'Netflix basic with Ads'], 'Title': 'Captain Underpants: The First Epic Movie'}, page_content=\"Overview: Based on the bestselling book series, this outrageous comedy tells the story of George and Harold,  two overly imaginative pranksters who hypnotize their principal into thinking he’s an enthusiastic, yet dimwitted, superhero named Captain Underpants.. Keywords: friendship, based on novel or book, superhero, underwear, villain, comic book, school, principal, based on children's book, grade school, sock puppet, excited, vibrant\"),\n",
              "  Document(metadata={'Actors': ['Jeff Anderson', 'Kevin Smith', 'Ben Affleck', \"Brian O'Halloran\", 'Jason Mewes'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['Kevin Smith'], 'Genre': ['Comedy'], 'Language': 'English', 'Production Companies': ['Dimension Films', 'View Askew Productions'], 'Release Year': 2001.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 104.0, 'Stream': ['Amazon Prime Video', 'fuboTV', 'Epix Amazon Channel', 'Paramount Plus', 'Paramount Plus Apple TV Channel', 'Paramount+ Amazon Channel', 'MGM Plus Roku Premium Channel', 'MGM Plus', 'Showtime Apple TV Channel', 'Amazon Prime Video with Ads'], 'Title': 'Jay and Silent Bob Strike Back'}, page_content='Overview: When Jay and Silent Bob learn that their comic-book alter egos, Bluntman and Chronic, have been sold to Hollywood as part of a big-screen movie that leaves them out of any royalties, the pair travels to Tinseltown to sabotage the production.. Keywords: experiment, movie business, comic book, breaking the fourth wall, self mocking, monkey actor, gigantic hand'),\n",
              "  Document(metadata={'Actors': ['Anna Faris', 'Shawn Wayans', 'Regina Hall', 'Jon Abrahams', 'Marlon Wayans'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['Keenen Ivory Wayans'], 'Genre': ['Comedy'], 'Language': 'English', 'Production Companies': ['Brad Grey Pictures', 'Gold/Miller Productions', 'Wayans Bros. Entertainment', 'Dimension Films'], 'Release Year': 2000.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 88.0, 'Stream': [''], 'Title': 'Scary Movie'}, page_content='Overview: A familiar-looking group of teenagers find themselves being stalked by a more-than-vaguely recognizable masked killer! As the victims begin to pile up and the laughs pile on, none of your favorite scary movies escape the razor-sharp satire of this outrageously funny parody!. Keywords: high school, psychopath, garage, satire, parody, crude humor, spoof, horror spoof, drugs, aftercreditsstinger, horror parody'),\n",
              "  Document(metadata={'Actors': ['Kelsey Grammer', 'Sarah Jessica Parker', 'Christina Hendricks', 'Pierce Brosnan', 'Greg Kinnear'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home'], 'Directors': ['Douglas McGrath'], 'Genre': ['Romance', 'Comedy'], 'Language': 'English', 'Production Companies': ['The Weinstein Company'], 'Release Year': 2011.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home'], 'Runtime (minutes)': 89.0, 'Stream': ['Max', 'Max Amazon Channel', 'Starz Apple TV Channel'], 'Title': \"I Don't Know How She Does It\"}, page_content='Overview: A comedy centered on the life of Kate Reddy, a finance executive who is the breadwinner for her husband and two kids.. Keywords: pregnancy, family vacation, widower, working mum, in-laws'),\n",
              "  Document(metadata={'Actors': ['Kerry Condon', 'Gary Lydon', 'Barry Keoghan', 'Brendan Gleeson', 'Colin Farrell'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['Martin McDonagh'], 'Genre': ['Drama', 'Comedy'], 'Language': 'English', 'Production Companies': ['Searchlight Pictures', 'Blueprint Pictures', 'Film4 Productions', 'TSG Entertainment'], 'Release Year': 2022.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'Spectrum On Demand'], 'Runtime (minutes)': 114.0, 'Stream': [''], 'Title': 'The Banshees of Inisherin'}, page_content='Overview: Two lifelong friends find themselves at an impasse when one abruptly ends their relationship, with alarming consequences for both of them.. Keywords: friendship, island, donkey, dark comedy, irish civil war (1922-23), church, ireland, drinking, former best friend, self mutilation, fiddle, 1920s, brother sister relationship, pub'),\n",
              "  Document(metadata={'Actors': ['Colin Farrell', 'Barry Keoghan', 'Brendan Gleeson', 'Kerry Condon', 'Gary Lydon'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['Martin McDonagh'], 'Genre': ['Drama', 'Comedy'], 'Language': 'English', 'Production Companies': ['Searchlight Pictures', 'Blueprint Pictures', 'Film4 Productions', 'TSG Entertainment'], 'Release Year': 2022.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'Spectrum On Demand'], 'Runtime (minutes)': 114.0, 'Stream': [''], 'Title': 'The Banshees of Inisherin'}, page_content='Overview: Two lifelong friends find themselves at an impasse when one abruptly ends their relationship, with alarming consequences for both of them.. Keywords: friendship, island, donkey, dark comedy, irish civil war (1922-23), church, ireland, drinking, former best friend, self mutilation, fiddle, 1920s, brother sister relationship, pub'),\n",
              "  Document(metadata={'Actors': ['Jason Mantzoukas', 'Sayed Badreya', 'Anna Faris', 'Ben Kingsley', 'Sacha Baron Cohen'], 'Buy': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store', 'AMC on Demand'], 'Directors': ['Larry Charles'], 'Genre': ['Comedy'], 'Language': 'English', 'Production Companies': ['Paramount Pictures', 'Four by Two', 'Berg Mandel Schaffer Productions', 'Scott Rudin Productions'], 'Release Year': 2012.0, 'Rent': ['Apple TV', 'Amazon Video', 'Google Play Movies', 'YouTube', 'Fandango At Home', 'Microsoft Store'], 'Runtime (minutes)': 83.0, 'Stream': [''], 'Title': 'The Dictator'}, page_content=\"Overview: The heroic story of a dictator who risks his life to ensure that democracy would never come to the country he so lovingly oppressed.. Keywords: petrol, culture clash, dictator, coup d'etat, satire, parody, uncle, conspiracy, female soldier, united nations, weapon of mass destruction, dissident, grocery store, identity swap, ironic, hilarious\")],\n",
              " 'answer': '- [Captain Underpants: The First Epic Movie](https://www.netflix.com/title/80100100):\\n    - Runtime: 89 minutes\\n    - Release Year: 2017\\n    - This animated comedy is a delightful adaptation of the beloved children\\'s book series. It follows the hilarious antics of two prankster friends who hypnotize their principal into becoming a superhero. The vibrant animation and playful humor make it a perfect choice for family viewing, ensuring laughs for both kids and adults alike.\\n\\n- [Evolution](https://www.amazon.com/Evolution-David-Duchovny/dp/B000I9F8D4):\\n    - Runtime: 101 minutes\\n    - Release Year: 2001\\n    - This sci-fi comedy brings a unique twist to the genre, as it combines humor with an alien invasion plot. With a stellar cast including David Duchovny and Julianne Moore, the film delivers a mix of laughs and action as the characters navigate the chaos caused by extraterrestrial life forms. It\\'s a fun ride that keeps you entertained from start to finish.\\n\\n- [Jay and Silent Bob Strike Back](https://www.amazon.com/Jay-Silent-Bob-Strike-Back/dp/B000I9F8D4):\\n    - Runtime: 104 minutes\\n    - Release Year: 2001\\n    - This film is a must-watch for fans of Kevin Smith\\'s unique brand of humor. Following the misadventures of Jay and Silent Bob as they attempt to sabotage a movie based on their comic book characters, it’s filled with self-referential jokes and a plethora of cameos. It\\'s a hilarious take on the film industry that will resonate with anyone who appreciates a good comedy.\\n\\n- [Scary Movie](https://www.amazon.com/Scary-Movie-Anna-Faris/dp/B000I9F8D4):\\n    - Runtime: 88 minutes\\n    - Release Year: 2000\\n    - As a parody of popular horror films, \"Scary Movie\" delivers a blend of crude humor and clever satire. It pokes fun at the clichés of the genre while providing plenty of laugh-out-loud moments. If you\\'re in the mood for a comedy that doesn\\'t take itself too seriously, this film is a perfect choice.\\n\\n- [The Dictator](https://www.amazon.com/Dictator-Sacha-Baron-Cohen/dp/B0078G8D8A):\\n    - Runtime: 83 minutes\\n    - Release Year: 2012\\n    - This satirical comedy features Sacha Baron Cohen as a dictator who goes to great lengths to ensure his oppressive regime remains intact. The film is filled with outrageous humor and sharp social commentary, making it both entertaining and thought-provoking. If you\\'re looking for a comedy that pushes boundaries, \"The Dictator\" is sure to deliver.'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **chat_app.py**"
      ],
      "metadata": {
        "id": "WP_v1zyQnBTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nessa etapa utiliza-se o que foi feito anteriormente, juntando todas as funções da RAG em uma classe: \"FilmSearch\", juntando com funções para gerar as respostas."
      ],
      "metadata": {
        "id": "Vl7MASwDnkb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Langchain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.chains.query_constructor.base import AttributeInfo\n",
        "from langchain.retrievers.self_query.pinecone import PineconeTranslator\n",
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.chains.query_constructor.base import (\n",
        "    StructuredQueryOutputParser,\n",
        "    get_query_constructor_prompt,\n",
        ")\n",
        "\n",
        "# Pinecone\n",
        "from pinecone import Pinecone\n",
        "\n",
        "# General\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "\n",
        "class FilmSearch:\n",
        "    RETRIEVER_MODEL_NAME = \"gpt-4o\"\n",
        "    SUMMARY_MODEL_NAME = \"gpt-4o-mini\"\n",
        "    constructor_prompt = None\n",
        "    vectorstore = None\n",
        "    retriever = None\n",
        "    rag_chain_with_source = None\n",
        "\n",
        "    def __init__(self, openai_api_key, pinecone_api_key, pinecone_index_name):\n",
        "        load_dotenv()\n",
        "        self.initialize_query_constructor()\n",
        "        self.initialize_vector_store(\n",
        "            openai_api_key, pinecone_api_key, pinecone_index_name)\n",
        "        self.initialize_retriever(openai_api_key)\n",
        "        self.initialize_chat_model(openai_api_key)\n",
        "\n",
        "    def initialize_query_constructor(self):\n",
        "        document_content_description = \"Brief overview of a movie, along with keywords\"\n",
        "\n",
        "        # Define allowed comparators list\n",
        "        allowed_comparators = [\n",
        "            \"$eq\",  # Equal to (number, string, boolean)\n",
        "            \"$ne\",  # Not equal to (number, string, boolean)\n",
        "            \"$gt\",  # Greater than (number)\n",
        "            \"$gte\",  # Greater than or equal to (number)\n",
        "            \"$lt\",  # Less than (number)\n",
        "            \"$lte\",  # Less than or equal to (number)\n",
        "            \"$in\",  # In array (string or number)\n",
        "            \"$nin\",  # Not in array (string or number)\n",
        "            \"$exists\",  # Has the specified metadata field (boolean)\n",
        "        ]\n",
        "\n",
        "        examples = [\n",
        "            (\n",
        "                \"I'm looking for a sci-fi comedy released after 2021.\",\n",
        "                {\n",
        "                    \"query\": \"sci-fi comedy\",\n",
        "                    \"filter\": \"and(eq('Genre', 'Science Fiction'), eq('Genre', 'Comedy'), gt('Release Year', 2021))\",\n",
        "                },\n",
        "            ),\n",
        "            (\n",
        "                \"Show me critically acclaimed dramas without Tom Hanks.\",\n",
        "                {\n",
        "                    \"query\": \"critically acclaimed drama\",\n",
        "                    \"filter\": \"and(eq('Genre', 'Drama'), nin('Actors', ['Tom Hanks']))\",\n",
        "                },\n",
        "            ),\n",
        "            (\n",
        "                \"Recommend some films by Yorgos Lanthimos.\",\n",
        "                {\n",
        "                    \"query\": \"Yorgos Lanthimos\",\n",
        "                    \"filter\": 'in(\"Directors\", [\"Yorgos Lanthimos]\")',\n",
        "                },\n",
        "            ),\n",
        "            (\n",
        "                \"Films similar to Yorgos Lanthmios movies.\",\n",
        "                {\n",
        "                    \"query\": \"Dark comedy, absurd, Greek Weird Wave\",\n",
        "                    \"filter\": 'NO_FILTER',\n",
        "                },\n",
        "            ),\n",
        "            (\n",
        "                \"Find me thrillers with a strong female lead released between 2015 and 2020.\",\n",
        "                {\n",
        "                    \"query\": \"thriller strong female lead\",\n",
        "                    \"filter\": \"and(eq('Genre', 'Thriller'), gt('Release Year', 2015), lt('Release Year', 2021))\",\n",
        "                },\n",
        "            ),\n",
        "            (\n",
        "                \"Find me highly rated drama movies in English that are less than 2 hours long\",\n",
        "                {\n",
        "                    \"query\": \"Highly rated drama English under 2 hours\",\n",
        "                    \"filter\": 'and(eq(\"Genre\", \"Drama\"), eq(\"Language\", \"English\"), lt(\"Runtime (minutes)\", 120))',\n",
        "                },\n",
        "            ),\n",
        "        ]\n",
        "\n",
        "        metadata_field_info = [\n",
        "            AttributeInfo(\n",
        "                name=\"Title\", description=\"The title of the movie\", type=\"string\"),\n",
        "            AttributeInfo(name=\"Runtime (minutes)\",\n",
        "                          description=\"The runtime of the movie in minutes\", type=\"integer\"),\n",
        "            AttributeInfo(name=\"Language\",\n",
        "                          description=\"The language of the movie\", type=\"string\"),\n",
        "            AttributeInfo(name=\"Release Year\",\n",
        "                          description=\"The release year of the movie\", type=\"integer\"),\n",
        "            AttributeInfo(name=\"Genre\", description=\"The genre of the movie\",\n",
        "                          type=\"string or list[string]\"),\n",
        "            AttributeInfo(name=\"Actors\", description=\"The actors in the movie\",\n",
        "                          type=\"string or list[string]\"),\n",
        "            AttributeInfo(name=\"Directors\", description=\"The directors of the movie\",\n",
        "                          type=\"string or list[string]\"),\n",
        "            AttributeInfo(name=\"Stream\", description=\"The streaming platforms for the movie\",\n",
        "                          type=\"string or list[string]\"),\n",
        "            AttributeInfo(name=\"Buy\", description=\"The platforms where the movie can be bought\",\n",
        "                          type=\"string or list[string]\"),\n",
        "            AttributeInfo(name=\"Rent\", description=\"The platforms where the movie can be rented\",\n",
        "                          type=\"string or list[string]\"),\n",
        "            AttributeInfo(name=\"Production Companies\",\n",
        "                          description=\"The production companies of the movie\", type=\"string or list[string]\"),\n",
        "        ]\n",
        "\n",
        "        self.constructor_prompt = get_query_constructor_prompt(\n",
        "            document_content_description,\n",
        "            metadata_field_info,\n",
        "            allowed_comparators=allowed_comparators,\n",
        "            examples=examples,\n",
        "        )\n",
        "\n",
        "    def initialize_vector_store(self, open_ai_key, pinecone_api_key, pinecone_index_name):\n",
        "        pc = Pinecone(api_key=pinecone_api_key)\n",
        "\n",
        "        # Target index and check status\n",
        "        pc_index = pc.Index(pinecone_index_name)\n",
        "\n",
        "        embeddings = OpenAIEmbeddings(model='text-embedding-ada-002',\n",
        "                                      api_key=open_ai_key)\n",
        "\n",
        "        self.vectorstore = PineconeVectorStore(\n",
        "            pc_index, embeddings\n",
        "        )\n",
        "\n",
        "    def initialize_retriever(self, open_ai_key):\n",
        "        query_model = ChatOpenAI(\n",
        "            model=self.RETRIEVER_MODEL_NAME,\n",
        "            temperature=0,\n",
        "            streaming=True,\n",
        "            api_key=open_ai_key\n",
        "        )\n",
        "\n",
        "        output_parser = StructuredQueryOutputParser.from_components()\n",
        "        query_constructor = self.constructor_prompt | query_model | output_parser\n",
        "\n",
        "        self.retriever = SelfQueryRetriever(\n",
        "            query_constructor=query_constructor,\n",
        "            vectorstore=self.vectorstore,\n",
        "            structured_query_translator=PineconeTranslator(),\n",
        "            search_kwargs={'k': 10}\n",
        "        )\n",
        "\n",
        "    def initialize_chat_model(self, open_ai_key):\n",
        "        def format_docs(docs):\n",
        "            return \"\\n\\n\".join(f\"{doc.page_content}\\n\\nMetadata: {doc.metadata}\" for doc in docs)\n",
        "\n",
        "        chat_model = ChatOpenAI(\n",
        "            model=self.SUMMARY_MODEL_NAME,\n",
        "            temperature=0,\n",
        "            streaming=True,\n",
        "            api_key=open_ai_key\n",
        "        )\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "                (\n",
        "                    'system',\n",
        "                    \"\"\"\n",
        "                    Your goal is to recommend films to users based on their\n",
        "                    query and the retrieved context. If a retrieved film doesn't seem\n",
        "                    relevant, omit it from your response. If your context is empty\n",
        "                    or none of the retrieved films are relevant, do not recommend films, but instead\n",
        "                    tell the user you couldn't find any films that match their query.\n",
        "                    Aim for three to five film recommendations, as long as the films are relevant. You cannot\n",
        "                    recommend more than five films. Your recommendation should\n",
        "                    be relevant, original, and at least two to three sentences\n",
        "                    long.\n",
        "\n",
        "                    YOU CANNOT RECOMMEND A FILM IF IT DOES NOT APPEAR IN YOUR\n",
        "                    CONTEXT.\n",
        "\n",
        "                    # TEMPLATE FOR OUTPUT\n",
        "                    - **Title of Film**:\n",
        "                        - Runtime:\n",
        "                        - Release Year:\n",
        "                        - Streaming:\n",
        "                        - (Your reasoning for recommending this film)\n",
        "\n",
        "                    Question: {question}\n",
        "                    Context: {context}\n",
        "                    \"\"\"\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Create a chatbot Question & Answer chain from the retriever\n",
        "        rag_chain_from_docs = (\n",
        "            RunnablePassthrough.assign(\n",
        "                context=(lambda x: format_docs(x[\"context\"])))\n",
        "            | prompt\n",
        "            | chat_model\n",
        "            | StrOutputParser()\n",
        "        )\n",
        "\n",
        "        self.rag_chain_with_source = RunnableParallel(\n",
        "            {\"context\": self.retriever, \"question\": RunnablePassthrough()}\n",
        "        ).assign(answer=rag_chain_from_docs)\n",
        "\n",
        "    def ask(self, query: str):\n",
        "        try:\n",
        "            for chunk in self.rag_chain_with_source.stream(query):\n",
        "                for key in chunk:\n",
        "                    if key == 'answer':\n",
        "                        yield chunk[key]\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "nGim7fE9iyEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Client**"
      ],
      "metadata": {
        "id": "Y4yMaFVsnUlb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui é um exemplo de como a consulta poderia ser feita por um usuário.\n",
        "\n",
        "Exemplo de input: A movie like Interstellar"
      ],
      "metadata": {
        "id": "IRDdhsCin_5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(input_text, openai_api_key):\n",
        "    chat = FilmSearch(OPENAI_API_KEY, PINECONE_KEY, PINECONE_INDEX_NAME)\n",
        "\n",
        "    # Inicialize uma string vazia para acumular os chunks\n",
        "    full_answer = \"\"\n",
        "\n",
        "    # Itere sobre cada chunk e acumule-os na string\n",
        "    for chunk in chat.ask(input_text):\n",
        "        full_answer += chunk  # Acumula o conteúdo do chunk na string\n",
        "\n",
        "    # Imprima a resposta completa ao final\n",
        "    print(\"Full Answer:\", full_answer)\n",
        "\n",
        "text = input(\"Wich kind of movie are you looking for? \")\n",
        "\n",
        "generate_response(text, openai_api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq8beupzjA4l",
        "outputId": "a96742e9-32ea-4eeb-fd48-6d4ffe019bbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wich kind of movie are you looking for? an interstellar like movie\n",
            "Full Answer: - **Title of Film**: Interstellar\n",
            "    - Runtime: 169 minutes\n",
            "    - Release Year: 2014\n",
            "    - Streaming: Amazon Prime Video, Epix Amazon Channel, Paramount Plus, MGM Plus\n",
            "    - \"Interstellar\" is a visually stunning and emotionally charged film that explores the depths of space travel and the complexities of human relationships. With its themes of time manipulation, family bonds, and the quest for survival in a dystopian future, it resonates deeply with fans of science fiction. The film's use of a wormhole to traverse vast distances in space mirrors the adventurous spirit of interstellar exploration, making it a perfect recommendation for those seeking a similar experience. \n",
            "\n",
            "- **Title of Film**: Project 'Gemini'\n",
            "    - Runtime: 98 minutes\n",
            "    - Release Year: 2022\n",
            "    - Streaming: Amazon Prime Video\n",
            "    - \"Project 'Gemini'\" presents a gripping narrative of humanity's struggle for survival in space after Earth’s resources are depleted. The film captures the essence of exploration and the unknown, as a crew finds themselves stranded on an alien planet. Its themes of survival and the challenges of space travel align well with the adventurous and thought-provoking nature of \"Interstellar.\"\n",
            "\n",
            "- **Title of Film**: Invasion\n",
            "    - Runtime: 129 minutes\n",
            "    - Release Year: 2020\n",
            "    - Streaming: Amazon Prime Video, Peacock Premium\n",
            "    - \"Invasion\" delves into the complexities of human-alien interactions and the survival of humanity in the face of extraterrestrial threats. The film's exploration of compassion amidst chaos and its focus on a young woman's journey in a world altered by alien forces provide a unique perspective on the human experience, akin to the emotional depth found in \"Interstellar.\" \n",
            "\n",
            "These films should satisfy your craving for interstellar-like adventures, combining elements of space exploration, human relationships, and the unknown.\n"
          ]
        }
      ]
    }
  ]
}